{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from EDA\n",
    "import pandas as pd\n",
    "train_df = pd.read_parquet(\"../data/train_clean.parquet\")\n",
    "valid_df = pd.read_parquet(\"../data/valid_clean.parquet\")\n",
    "holdout_df = pd.read_parquet(\"../data/holdout_clean.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7278841, 86)\n",
      "(1819711, 86)\n",
      "(1605627, 86)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape); print(valid_df.shape); print(holdout_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Protocol & Metrics\n",
    "\n",
    "**Goal.** Evaluate models for both **ranking performance** (under class imbalance) and **probability calibration**.\n",
    "\n",
    "**Data Split.**\n",
    "- All model tuning, selection, and calibration are performed on **`train_df` only**, using **3-fold stratified cross-validation** (`N_FOLDS=3`).\n",
    "- Both `valid_df` and `holdout_df` are strictly held out and used **only for final evaluation/reporting**.\n",
    "\n",
    "**Primary Metric.**\n",
    "- **AP (Average Precision / PR-AUC):** Captures ranking quality under strong class imbalance (positive rate ≈ 1.9%).\n",
    "\n",
    "**Calibration Metrics.**\n",
    "- **LogLoss:** Evaluates probability calibration quality.\n",
    "- **WLL (50:50 Weighted LogLoss):** Adjusts for class imbalance to allow fairer model comparison.\n",
    "\n",
    "**Leakage Policy.**\n",
    "- No information from `valid_df` or `holdout_df` is used during training, tuning, or early stopping.  \n",
    "  All model decisions are made **only from CV results on `train_df`**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Class ratios]\n",
      "  train  : pos=0.019075, neg=0.980925\n",
      "  valid  : pos=0.019074, neg=0.980926\n",
      "  holdout: pos=0.019075, neg=0.980925\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Setup \n",
    "# =========================================================\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score, log_loss\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import lightgbm as lgb\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# All CV later must use train-only folds\n",
    "N_FOLDS = 3\n",
    "\n",
    "TARGET_COL = \"clicked\"\n",
    "SEQ_COL    = \"seq\"  # excluded from modeling\n",
    "CAT_COLS_FIXED = [\n",
    "    \"gender\",\"age_group\",\"inventory_id\",\"day_of_week\",\"hour\",\n",
    "    \"l_feat_1\",\"l_feat_2\",\"l_feat_3\",\"l_feat_4\",\"l_feat_8\",\"l_feat_13\",\n",
    "    \"l_feat_16\",\"l_feat_18\",\"l_feat_19\",\"l_feat_20\",\"l_feat_21\",\n",
    "    \"l_feat_22\",\"l_feat_23\",\"l_feat_24\",\"l_feat_26\",\"l_feat_27\"\n",
    "]\n",
    "\n",
    "# --- helpers\n",
    "def cast_categoricals(df: pd.DataFrame, cat_cols):\n",
    "    out = df.copy()\n",
    "    for c in cat_cols:\n",
    "        if c in out.columns and not isinstance(out[c].dtype, CategoricalDtype):\n",
    "            out[c] = out[c].astype(\"category\")\n",
    "    return out\n",
    "\n",
    "train_df = cast_categoricals(train_df, CAT_COLS_FIXED)\n",
    "valid_df = cast_categoricals(valid_df, CAT_COLS_FIXED)\n",
    "if \"holdout_df\" in locals():\n",
    "    holdout_df = cast_categoricals(holdout_df, CAT_COLS_FIXED)\n",
    "\n",
    "# =========================================================\n",
    "# Fixed feature set (exclude target & seq). Tuning uses ONLY train via K-fold CV.\n",
    "# =========================================================\n",
    "EXCLUDE   = {TARGET_COL, SEQ_COL}\n",
    "feat_cols = [c for c in train_df.columns if c not in EXCLUDE]\n",
    "\n",
    "X_tr, y_tr = train_df[feat_cols], train_df[TARGET_COL].astype(int).to_numpy()\n",
    "X_va, y_va = valid_df[feat_cols], valid_df[TARGET_COL].astype(int).to_numpy()\n",
    "X_ho       = holdout_df[feat_cols] if \"holdout_df\" in locals() else None\n",
    "y_ho       = (holdout_df[TARGET_COL].astype(int).to_numpy()\n",
    "              if (\"holdout_df\" in locals() and TARGET_COL in holdout_df) else None)\n",
    "\n",
    "# =========================================================\n",
    "# Metrics helpers (AP, LogLoss, WLL)\n",
    "# =========================================================\n",
    "def weighted_log_loss(y_true, p, pos_weight=0.5, neg_weight=0.5, eps=1e-15):\n",
    "    p = np.clip(np.asarray(p, dtype=float), eps, 1.0 - eps)\n",
    "    y = np.asarray(y_true, dtype=int)\n",
    "    n_pos = max(int((y == 1).sum()), 0)\n",
    "    n_neg = max(int((y == 0).sum()), 0)\n",
    "    w_pos = (pos_weight / n_pos) if n_pos > 0 else 0.0\n",
    "    w_neg = (neg_weight / n_neg) if n_neg > 0 else 0.0\n",
    "    sw = np.where(y == 1, w_pos, w_neg)\n",
    "    return float(log_loss(y, p, sample_weight=sw, labels=[0, 1]))\n",
    "\n",
    "def competition_score(ap, wll):\n",
    "    return float(ap - wll)\n",
    "\n",
    "def compute_metrics(y_true, p):\n",
    "    ap  = average_precision_score(y_true, p)\n",
    "    nll = log_loss(y_true, p)\n",
    "    wll = weighted_log_loss(y_true, p, 0.5, 0.5)\n",
    "    return {\"AP\": ap, \"LogLoss\": nll, \"WLL\": wll}\n",
    "\n",
    "# audit class ratios\n",
    "def _ratio(y):\n",
    "    y = np.asarray(y)\n",
    "    return f\"pos={y.mean():.6f}, neg={1.0 - y.mean():.6f}\"\n",
    "\n",
    "print(\"[Class ratios]\")\n",
    "print(\"  train  :\", _ratio(y_tr))\n",
    "print(\"  valid  :\", _ratio(y_va))\n",
    "print(\"  holdout:\", _ratio(y_ho) if y_ho is not None else \"N/A (labels missing)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hg/v9v4slf113jb0w4kpzx5y_zw0000gn/T/ipykernel_6192/1119675554.py:37: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if c in df.columns and not pd.api.types.is_categorical_dtype(df[c]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LogReg(OHE)] Fold 1: train pos=0.019070, cv pos=0.019080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LogReg(OHE)] Fold 2: train pos=0.019075, cv pos=0.019070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LogReg(OHE)] Fold 3: train pos=0.019075, cv pos=0.019070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM(Default)] Fold 1: train pos=0.019070, cv pos=0.019080\n",
      "[LightGBM] [Info] Number of positive: 3814, number of negative: 196186\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10326\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 84\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.019070 -> initscore=-3.940385\n",
      "[LightGBM] [Info] Start training from score -3.940385\n",
      "[LightGBM(Default)] Fold 2: train pos=0.019075, cv pos=0.019070\n",
      "[LightGBM] [Info] Number of positive: 3815, number of negative: 196185\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10324\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 84\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.019075 -> initscore=-3.940117\n",
      "[LightGBM] [Info] Start training from score -3.940117\n",
      "[LightGBM(Default)] Fold 3: train pos=0.019075, cv pos=0.019070\n",
      "[LightGBM] [Info] Number of positive: 3815, number of negative: 196185\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10331\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 84\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.019075 -> initscore=-3.940117\n",
      "[LightGBM] [Info] Start training from score -3.940117\n",
      "[XGBoost(Default)] Fold 1: train pos=0.019070, cv pos=0.019080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hg/v9v4slf113jb0w4kpzx5y_zw0000gn/T/ipykernel_6192/1119675554.py:43: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(out[c]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XGBoost(Default)] Fold 2: train pos=0.019075, cv pos=0.019070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hg/v9v4slf113jb0w4kpzx5y_zw0000gn/T/ipykernel_6192/1119675554.py:43: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(out[c]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XGBoost(Default)] Fold 3: train pos=0.019075, cv pos=0.019070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hg/v9v4slf113jb0w4kpzx5y_zw0000gn/T/ipykernel_6192/1119675554.py:43: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(out[c]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (TRAIN K-fold CV only) — lower WLL/LogLoss are better; higher AP is better\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_428c3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_428c3_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_428c3_level0_col1\" class=\"col_heading level0 col1\" >AP_mean</th>\n",
       "      <th id=\"T_428c3_level0_col2\" class=\"col_heading level0 col2\" >AP_std</th>\n",
       "      <th id=\"T_428c3_level0_col3\" class=\"col_heading level0 col3\" >WLL_mean</th>\n",
       "      <th id=\"T_428c3_level0_col4\" class=\"col_heading level0 col4\" >WLL_std</th>\n",
       "      <th id=\"T_428c3_level0_col5\" class=\"col_heading level0 col5\" >LogLoss_mean</th>\n",
       "      <th id=\"T_428c3_level0_col6\" class=\"col_heading level0 col6\" >LogLoss_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_428c3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_428c3_row0_col0\" class=\"data row0 col0\" >LightGBM(Default)</td>\n",
       "      <td id=\"T_428c3_row0_col1\" class=\"data row0 col1\" >0.042527</td>\n",
       "      <td id=\"T_428c3_row0_col2\" class=\"data row0 col2\" >0.001616</td>\n",
       "      <td id=\"T_428c3_row0_col3\" class=\"data row0 col3\" >1.333233</td>\n",
       "      <td id=\"T_428c3_row0_col4\" class=\"data row0 col4\" >0.004809</td>\n",
       "      <td id=\"T_428c3_row0_col5\" class=\"data row0 col5\" >0.110837</td>\n",
       "      <td id=\"T_428c3_row0_col6\" class=\"data row0 col6\" >0.000338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_428c3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_428c3_row1_col0\" class=\"data row1 col0\" >XGBoost(Default)</td>\n",
       "      <td id=\"T_428c3_row1_col1\" class=\"data row1 col1\" >0.040019</td>\n",
       "      <td id=\"T_428c3_row1_col2\" class=\"data row1 col2\" >0.001335</td>\n",
       "      <td id=\"T_428c3_row1_col3\" class=\"data row1 col3\" >2.125304</td>\n",
       "      <td id=\"T_428c3_row1_col4\" class=\"data row1 col4\" >0.028454</td>\n",
       "      <td id=\"T_428c3_row1_col5\" class=\"data row1 col5\" >0.104368</td>\n",
       "      <td id=\"T_428c3_row1_col6\" class=\"data row1 col6\" >0.000467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_428c3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_428c3_row2_col0\" class=\"data row2 col0\" >LogReg(OHE)</td>\n",
       "      <td id=\"T_428c3_row2_col1\" class=\"data row2 col1\" >0.039996</td>\n",
       "      <td id=\"T_428c3_row2_col2\" class=\"data row2 col2\" >0.001288</td>\n",
       "      <td id=\"T_428c3_row2_col3\" class=\"data row2 col3\" >0.664000</td>\n",
       "      <td id=\"T_428c3_row2_col4\" class=\"data row2 col4\" >0.001439</td>\n",
       "      <td id=\"T_428c3_row2_col5\" class=\"data row2 col5\" >0.655804</td>\n",
       "      <td id=\"T_428c3_row2_col6\" class=\"data row2 col6\" >0.002371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x6fe93fbf0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Baseline comparison (LogReg vs. LightGBM vs. XGBoost) on TRAIN via K-fold CV only\n",
    "# - No leakage: uses only train_df (no valid/holdout)\n",
    "# - Metrics: LogLoss, AP (PR-AUC), WLL(50:50)\n",
    "# =========================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score, log_loss\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "BASE_N = 300_000\n",
    "RNG = check_random_state(SEED)\n",
    "\n",
    "# helpers\n",
    "def stratified_sample(df: pd.DataFrame, n: int, ycol: str, seed: int) -> pd.DataFrame:\n",
    "    if (n is None) or (n >= len(df)):\n",
    "        return df.sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "    pos = df[df[ycol] == 1]\n",
    "    neg = df[df[ycol] == 0]\n",
    "    rate = pos.shape[0] / max(len(df), 1)\n",
    "    n_pos = max(1, int(round(n * rate)))\n",
    "    n_neg = max(1, n - n_pos)\n",
    "    pos_s = pos.sample(min(n_pos, len(pos)), random_state=seed)\n",
    "    neg_s = neg.sample(min(n_neg, len(neg)), random_state=seed)\n",
    "    return pd.concat([pos_s, neg_s]).sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "def cast_categoricals_inplace(df: pd.DataFrame, cat_cols: list[str]):\n",
    "    for c in cat_cols:\n",
    "        if c in df.columns and not pd.api.types.is_categorical_dtype(df[c]):\n",
    "            df[c] = df[c].astype(\"category\")\n",
    "\n",
    "def cat_to_codes(df: pd.DataFrame, cat_cols: list[str]) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for c in [c for c in cat_cols if c in out.columns]:\n",
    "        if pd.api.types.is_categorical_dtype(out[c]):\n",
    "            out[c] = out[c].cat.codes\n",
    "        elif out[c].dtype.name == \"object\":\n",
    "            out[c] = out[c].astype(\"category\").cat.codes\n",
    "    return out\n",
    "\n",
    "# features\n",
    "EXCLUDE = {TARGET_COL, SEQ_COL}\n",
    "feat_cols = [c for c in train_df.columns if c not in EXCLUDE]\n",
    "\n",
    "# training subset for fast CV baseline\n",
    "tr_s  = stratified_sample(train_df, BASE_N, TARGET_COL, SEED)\n",
    "Xtr_s = tr_s[feat_cols].copy()\n",
    "ytr_s = tr_s[TARGET_COL].astype(int).to_numpy()\n",
    "\n",
    "# cleanup\n",
    "obj_cols_tr = Xtr_s.select_dtypes(include=['object']).columns.tolist()\n",
    "if obj_cols_tr:\n",
    "    Xtr_s.drop(columns=obj_cols_tr, inplace=True, errors=\"ignore\")\n",
    "cat_present = [c for c in CAT_COLS_FIXED if c in feat_cols]\n",
    "cast_categoricals_inplace(Xtr_s, cat_present)\n",
    "\n",
    "# Logistic Regression (OHE baseline)\n",
    "num_cols = [c for c in feat_cols if c not in cat_present]\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=True)\n",
    "\n",
    "prep_lr = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", ohe, [c for c in cat_present if c in Xtr_s.columns]),\n",
    "        (\"num\", SimpleImputer(strategy=\"mean\"), [c for c in num_cols if c in Xtr_s.columns]),\n",
    "    ],\n",
    "    sparse_threshold=0.3\n",
    ")\n",
    "\n",
    "lr = Pipeline([\n",
    "    (\"prep\", prep_lr),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\", solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "# LightGBM default baseline (per-fold scale_pos_weight)\n",
    "lgbm_base = dict(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.05,\n",
    "    objective=\"binary\",\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# XGBoost default baseline (per-fold scale_pos_weight)\n",
    "xgb_base = dict(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1,\n",
    "    early_stopping_rounds=100  # XGBoost early stopping을 모델 초기화 시 설정\n",
    ")\n",
    "\n",
    "# K-fold CV on train only\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "def _cv_eval(model_name: str):\n",
    "    ap_scores, wll_scores, nll_scores = [], [], []\n",
    "    fold_idx = 0\n",
    "    for tr_idx, va_idx in skf.split(Xtr_s, ytr_s):\n",
    "        fold_idx += 1\n",
    "        Xtr, Xcv = Xtr_s.iloc[tr_idx], Xtr_s.iloc[va_idx]\n",
    "        ytr, ycv = ytr_s[tr_idx], ytr_s[va_idx]\n",
    "\n",
    "        print(f\"[{model_name}] Fold {fold_idx}: train pos={ytr.mean():.6f}, cv pos={ycv.mean():.6f}\")\n",
    "\n",
    "        if model_name == \"LogReg(OHE)\":\n",
    "            model = lr\n",
    "            Xtr_fit, Xcv_fit = Xtr, Xcv\n",
    "\n",
    "        elif model_name == \"LightGBM(Default)\":\n",
    "            params = dict(lgbm_base)\n",
    "            pos_tr = int(ytr.sum()); neg_tr = len(ytr) - pos_tr\n",
    "            params[\"scale_pos_weight\"] = float(neg_tr / max(pos_tr, 1))\n",
    "            model = lgb.LGBMClassifier(**params)\n",
    "            Xtr_fit, Xcv_fit = Xtr, Xcv\n",
    "\n",
    "        elif model_name == \"XGBoost(Default)\":\n",
    "            params = dict(xgb_base)\n",
    "            pos_tr = int(ytr.sum()); neg_tr = len(ytr) - pos_tr\n",
    "            params[\"scale_pos_weight\"] = float(neg_tr / max(pos_tr, 1))\n",
    "            model = xgb.XGBClassifier(**params)\n",
    "            Xtr_fit = cat_to_codes(Xtr, cat_present)\n",
    "            Xcv_fit = cat_to_codes(Xcv, cat_present)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model_name={model_name}\")\n",
    "\n",
    "        # ---- fit per model ----\n",
    "        if model_name == \"LogReg(OHE)\":\n",
    "            model.fit(Xtr_fit, ytr)\n",
    "\n",
    "        elif model_name == \"LightGBM(Default)\":\n",
    "            model.fit(\n",
    "                Xtr_fit, ytr,\n",
    "                eval_set=[(Xcv_fit, ycv)],\n",
    "                eval_metric=\"binary_logloss\",\n",
    "                callbacks=[lgb.early_stopping(100, verbose=False)]\n",
    "            )\n",
    "\n",
    "        elif model_name == \"XGBoost(Default)\":\n",
    "            model.fit(\n",
    "                Xtr_fit, ytr,\n",
    "                eval_set=[(Xcv_fit, ycv)],\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "        p = model.predict_proba(Xcv_fit)[:, 1] if hasattr(model, \"predict_proba\") else model.predict(Xcv_fit)\n",
    "        ap_scores.append(average_precision_score(ycv, p))\n",
    "        wll_scores.append(weighted_log_loss(ycv, p, 0.5, 0.5))\n",
    "        nll_scores.append(log_loss(ycv, p))\n",
    "\n",
    "    return {\n",
    "        \"AP_mean\": float(np.mean(ap_scores)),   \"AP_std\": float(np.std(ap_scores)),\n",
    "        \"WLL_mean\": float(np.mean(wll_scores)), \"WLL_std\": float(np.std(wll_scores)),\n",
    "        \"LogLoss_mean\": float(np.mean(nll_scores)), \"LogLoss_std\": float(np.std(nll_scores)),\n",
    "    }\n",
    "\n",
    "res_lr  = _cv_eval(\"LogReg(OHE)\")\n",
    "res_lgb = _cv_eval(\"LightGBM(Default)\")\n",
    "res_xgb = _cv_eval(\"XGBoost(Default)\")\n",
    "\n",
    "# report (primary sort by AP, then WLL)\n",
    "baseline_df = (\n",
    "    pd.DataFrame([\n",
    "        {\"Model\": \"LogReg(OHE)\",        **res_lr},\n",
    "        {\"Model\": \"LightGBM(Default)\",  **res_lgb},\n",
    "        {\"Model\": \"XGBoost(Default)\",   **res_xgb},\n",
    "    ])\n",
    "    .sort_values([\"AP_mean\", \"WLL_mean\"], ascending=[False, True])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "_fmt = {\n",
    "    \"AP_mean\":\"{:.6f}\", \"AP_std\":\"{:.6f}\",\n",
    "    \"WLL_mean\":\"{:.6f}\", \"WLL_std\":\"{:.6f}\",\n",
    "    \"LogLoss_mean\":\"{:.6f}\", \"LogLoss_std\":\"{:.6f}\",\n",
    "}\n",
    "cols = [\"Model\",\"AP_mean\",\"AP_std\",\"WLL_mean\",\"WLL_std\",\"LogLoss_mean\",\"LogLoss_std\"]\n",
    "\n",
    "print(\"Baseline (TRAIN K-fold CV only) — lower WLL/LogLoss are better; higher AP is better\")\n",
    "display(baseline_df[cols].style.format(_fmt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model Comparison (Train CV Only)\n",
    "\n",
    "Three models were compared using 3-fold CV on the training data:\n",
    "\n",
    "Interpretation:\n",
    "- LightGBM achieved the best balance between ranking performance (AP) and calibrated loss (WLL).\n",
    "- XGBoost yielded slightly better log-loss but suffered from overconfident predictions (high WLL).\n",
    "- LogReg performed competitively in WLL but lagged in AP and LogLoss.\n",
    "\n",
    "Decision:\n",
    "\n",
    "- Despite XGBoost showing decent performance, LightGBM was selected for further tuning due to its faster training and memory efficiency on large-scale data (~10M rows), aligning better with computational constraints.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM Tuning Plan (Leak-Free, Train-CV Only)\n",
    "\n",
    "**Objective**  \n",
    "Maximize **PR-AUC (AP)** under class imbalance.  \n",
    "Ensure good probability calibration via **LogLoss** and **WLL (50:50)**.  \n",
    "Final evaluation will report all three metrics for robustness.\n",
    "\n",
    "---\n",
    "\n",
    "**Leak-Free Tuning Protocol**\n",
    "\n",
    "- All tuning (Optuna search, early stopping, model selection) uses only `train_df` via **K-fold CV**.\n",
    "- **Isotonic calibration** is also fit using **OOF predictions from train folds only**.\n",
    "- `valid_df` and `holdout_df` are **never used** during tuning or calibration.\n",
    "- After tuning:\n",
    "  - Best config is trained on **full train_df**\n",
    "  - Isotonic calibration is applied\n",
    "  - Evaluation is run **once on holdout_df**\n",
    "\n",
    "---\n",
    "\n",
    "**Tuning Stages**\n",
    "\n",
    "| Stage | Purpose                | Trials  | Description |\n",
    "|------:|-------------------------|--------:|-------------|\n",
    "| 1     | Broad exploration       | 100–200 | Tune tree size, regularization, sampling, `scale_pos_weight` vs `is_unbalance` |\n",
    "| 2     | Focused exploitation    | 30–50   | Zoom into top 10% trials from Stage 1 |\n",
    "| 3     | Final model & calibration | 1     | Train best config on full train, calibrate with OOF isotonic, evaluate once on holdout |\n",
    "\n",
    "---\n",
    "\n",
    "**Reporting**\n",
    "\n",
    "- **Baseline Comparison (Train CV):** LogReg(OHE) vs LightGBM(Default)\n",
    "- **Tuning Summary:** Top trials sorted by CV-AP and CV-LogLoss\n",
    "- **Final Holdout Evaluation:** AP, LogLoss, WLL, and predicted probability statistics\n",
    "\n",
    "---\n",
    "\n",
    "**Reproducibility**\n",
    "\n",
    "- Controlled by top-level constants: `SEED`, `N_FOLDS`, optional subsample sizes.\n",
    "- All artifacts (trials, params, models, calibration objects, holdout predictions) saved to:\n",
    "  `./artifacts/optuna_lgbm/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hg/v9v4slf113jb0w4kpzx5y_zw0000gn/T/ipykernel_77034/3042281080.py:38: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xt[c]):\n",
      "[I 2025-09-14 14:36:57,610] A new study created in memory with name: lgbm_tune_ap\n",
      "Best trial: 0. Best value: -0.0492498:   1%|          | 1/120 [00:24<49:05, 24.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 14:37:22,369] Trial 0 finished with value: -0.04924975312172609 and parameters: {'learning_rate': 0.05872180976996895, 'num_leaves': 69, 'max_depth': 8, 'min_data_in_leaf': 569, 'feature_fraction': 0.637113266198345, 'bagging_fraction': 0.9918973453550037, 'lambda_l1': 3.9862455750819157, 'lambda_l2': 0.7214066901273297, 'use_scale_pos_weight': False}. Best is trial 0 with value: -0.04924975312172609.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.0492498:   2%|▏         | 2/120 [06:36<7:30:32, 229.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 14:43:34,495] Trial 1 finished with value: -0.04660062608922394 and parameters: {'learning_rate': 0.1637086811099485, 'num_leaves': 48, 'max_depth': 7, 'min_data_in_leaf': 104, 'feature_fraction': 0.829322617938997, 'bagging_fraction': 0.8675948017354721, 'lambda_l1': 9.630881697033352, 'lambda_l2': 5.385645428983777, 'use_scale_pos_weight': False}. Best is trial 0 with value: -0.04924975312172609.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.0492498:   2%|▎         | 3/120 [06:55<4:19:43, 133.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 14:43:53,565] Trial 2 finished with value: -0.04283949941071474 and parameters: {'learning_rate': 0.024529966112888157, 'num_leaves': 33, 'max_depth': 9, 'min_data_in_leaf': 410, 'feature_fraction': 0.7714554319342305, 'bagging_fraction': 0.6394799680976904, 'lambda_l1': 5.5618728062014196, 'lambda_l2': 5.006526872177577, 'use_scale_pos_weight': True}. Best is trial 0 with value: -0.04924975312172609.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.0492498:   3%|▎         | 4/120 [07:25<2:58:21, 92.26s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 14:44:23,074] Trial 3 finished with value: -0.04124933703336311 and parameters: {'learning_rate': 0.10820431278637536, 'num_leaves': 104, 'max_depth': 10, 'min_data_in_leaf': 1286, 'feature_fraction': 0.7619508099731962, 'bagging_fraction': 0.6676129195724912, 'lambda_l1': 9.761930960092306, 'lambda_l2': 9.825119587022586, 'use_scale_pos_weight': True}. Best is trial 0 with value: -0.04924975312172609.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.0492498:   4%|▍         | 5/120 [12:00<5:03:27, 158.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 14:48:58,537] Trial 4 finished with value: -0.04913786459310621 and parameters: {'learning_rate': 0.15910722794569382, 'num_leaves': 684, 'max_depth': 13, 'min_data_in_leaf': 387, 'feature_fraction': 0.6831646356192728, 'bagging_fraction': 0.8258400100916627, 'lambda_l1': 9.939086999281958, 'lambda_l2': 2.6485339947593345, 'use_scale_pos_weight': False}. Best is trial 0 with value: -0.04924975312172609.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.0492498:   5%|▌         | 6/120 [16:30<6:12:59, 196.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 14:53:28,599] Trial 5 finished with value: -0.04865593653090514 and parameters: {'learning_rate': 0.1875239286350963, 'num_leaves': 553, 'max_depth': 15, 'min_data_in_leaf': 2065, 'feature_fraction': 0.7891560122131501, 'bagging_fraction': 0.9906466715147224, 'lambda_l1': 1.8732924454622768, 'lambda_l2': 5.769590162200714, 'use_scale_pos_weight': False}. Best is trial 0 with value: -0.04924975312172609.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.0492498:   6%|▌         | 7/120 [17:05<4:30:23, 143.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 14:54:03,579] Trial 6 finished with value: -0.04606329131319414 and parameters: {'learning_rate': 0.04725263189629117, 'num_leaves': 304, 'max_depth': 15, 'min_data_in_leaf': 3748, 'feature_fraction': 0.884569895507688, 'bagging_fraction': 0.9989048963014185, 'lambda_l1': 8.34292441907503, 'lambda_l2': 4.444385205148541, 'use_scale_pos_weight': False}. Best is trial 0 with value: -0.04924975312172609.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.0492498:   7%|▋         | 8/120 [17:34<3:19:23, 106.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 14:54:31,699] Trial 7 finished with value: -0.044790329639851044 and parameters: {'learning_rate': 0.044151746306562184, 'num_leaves': 69, 'max_depth': 13, 'min_data_in_leaf': 1856, 'feature_fraction': 0.8867928686282193, 'bagging_fraction': 0.978492024458, 'lambda_l1': 4.03476003718631, 'lambda_l2': 6.130956525109762, 'use_scale_pos_weight': True}. Best is trial 0 with value: -0.04924975312172609.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.0492498:   8%|▊         | 9/120 [18:01<2:31:58, 82.15s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 14:54:59,604] Trial 8 finished with value: -0.04863394597374571 and parameters: {'learning_rate': 0.04602521891223152, 'num_leaves': 68, 'max_depth': 15, 'min_data_in_leaf': 1208, 'feature_fraction': 0.8236243021138038, 'bagging_fraction': 0.8374702779200801, 'lambda_l1': 1.8355784726318336, 'lambda_l2': 0.05812843479176433, 'use_scale_pos_weight': True}. Best is trial 0 with value: -0.04924975312172609.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.0492498:   8%|▊         | 10/120 [18:30<2:00:19, 65.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 14:55:28,252] Trial 9 finished with value: -0.04510001284692333 and parameters: {'learning_rate': 0.0213497301051022, 'num_leaves': 79, 'max_depth': 9, 'min_data_in_leaf': 1588, 'feature_fraction': 0.8319972686814134, 'bagging_fraction': 0.9772353159739894, 'lambda_l1': 5.534718190023384, 'lambda_l2': 3.9790402416808925, 'use_scale_pos_weight': True}. Best is trial 0 with value: -0.04924975312172609.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: -0.0503818:   9%|▉         | 11/120 [18:51<1:34:32, 52.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 14:55:49,478] Trial 10 finished with value: -0.05038184854992108 and parameters: {'learning_rate': 0.08734110143769208, 'num_leaves': 190, 'max_depth': 6, 'min_data_in_leaf': 194, 'feature_fraction': 0.6059273972549623, 'bagging_fraction': 0.7232359559366153, 'lambda_l1': 4.035576630234075, 'lambda_l2': 0.029722684758952234, 'use_scale_pos_weight': False}. Best is trial 10 with value: -0.05038184854992108.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: -0.0503818:  10%|█         | 12/120 [19:15<1:18:19, 43.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 14:56:13,479] Trial 11 finished with value: -0.047922585282500346 and parameters: {'learning_rate': 0.083346072727584, 'num_leaves': 173, 'max_depth': 6, 'min_data_in_leaf': 147, 'feature_fraction': 0.6004721564163064, 'bagging_fraction': 0.7299347149740509, 'lambda_l1': 3.4251618003270963, 'lambda_l2': 0.9334963740014431, 'use_scale_pos_weight': False}. Best is trial 10 with value: -0.05038184854992108.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: -0.0503818:  11%|█         | 13/120 [19:42<1:08:21, 38.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 14:56:39,907] Trial 12 finished with value: -0.047541991885420444 and parameters: {'learning_rate': 0.07373543163696136, 'num_leaves': 178, 'max_depth': 7, 'min_data_in_leaf': 248, 'feature_fraction': 0.6043285144046383, 'bagging_fraction': 0.7395526938464392, 'lambda_l1': 0.09346918559915185, 'lambda_l2': 1.8108400144699635, 'use_scale_pos_weight': False}. Best is trial 10 with value: -0.05038184854992108.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  12%|█▏        | 14/120 [20:01<57:24, 32.50s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 14:56:58,918] Trial 13 finished with value: -0.05075738128694907 and parameters: {'learning_rate': 0.11005399163831152, 'num_leaves': 158, 'max_depth': 6, 'min_data_in_leaf': 592, 'feature_fraction': 0.6745359259628316, 'bagging_fraction': 0.9166779100845361, 'lambda_l1': 6.389920369265148, 'lambda_l2': 0.05326688388224072, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  12%|█▎        | 15/120 [20:20<50:01, 28.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 14:57:18,444] Trial 14 finished with value: -0.04639179573900141 and parameters: {'learning_rate': 0.10398687406312936, 'num_leaves': 304, 'max_depth': 6, 'min_data_in_leaf': 226, 'feature_fraction': 0.9948894604843699, 'bagging_fraction': 0.9117527873254393, 'lambda_l1': 7.091135975435959, 'lambda_l2': 3.0542747094170966, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  13%|█▎        | 16/120 [20:58<54:28, 31.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 14:57:56,469] Trial 15 finished with value: -0.0429912649641673 and parameters: {'learning_rate': 0.1153356844646056, 'num_leaves': 148, 'max_depth': 11, 'min_data_in_leaf': 764, 'feature_fraction': 0.6928442324117084, 'bagging_fraction': 0.7594144720945689, 'lambda_l1': 7.2721406334169, 'lambda_l2': 7.816264539536152, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  14%|█▍        | 17/120 [21:19<48:30, 28.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 14:58:17,336] Trial 16 finished with value: -0.048796559980015225 and parameters: {'learning_rate': 0.12007326163518316, 'num_leaves': 313, 'max_depth': 6, 'min_data_in_leaf': 289, 'feature_fraction': 0.6881931054085115, 'bagging_fraction': 0.9042150355922408, 'lambda_l1': 6.559612424272374, 'lambda_l2': 1.8124972287224357, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  15%|█▌        | 18/120 [21:48<48:13, 28.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 14:58:45,972] Trial 17 finished with value: -0.049300209530700224 and parameters: {'learning_rate': 0.030427616149857086, 'num_leaves': 240, 'max_depth': 8, 'min_data_in_leaf': 792, 'feature_fraction': 0.7204988019886974, 'bagging_fraction': 0.6036086041869799, 'lambda_l1': 2.575859423967037, 'lambda_l2': 0.04652511407978649, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  16%|█▌        | 19/120 [22:56<1:07:37, 40.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 14:59:53,647] Trial 18 finished with value: -0.04712092241097827 and parameters: {'learning_rate': 0.0817122504757079, 'num_leaves': 464, 'max_depth': 11, 'min_data_in_leaf': 161, 'feature_fraction': 0.6556882969807271, 'bagging_fraction': 0.7681904738357798, 'lambda_l1': 5.036341874492813, 'lambda_l2': 1.8196178377485288, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  17%|█▋        | 20/120 [29:15<3:56:29, 141.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:06:12,627] Trial 19 finished with value: -0.045818918332246696 and parameters: {'learning_rate': 0.1417705161731653, 'num_leaves': 120, 'max_depth': 7, 'min_data_in_leaf': 552, 'feature_fraction': 0.723161228530444, 'bagging_fraction': 0.6827573991827021, 'lambda_l1': 6.621517514717109, 'lambda_l2': 7.433120652307903, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  18%|█▊        | 21/120 [29:35<2:53:50, 105.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:06:32,810] Trial 20 finished with value: -0.046343916553822605 and parameters: {'learning_rate': 0.06169435011351525, 'num_leaves': 234, 'max_depth': 8, 'min_data_in_leaf': 4730, 'feature_fraction': 0.6452334382812676, 'bagging_fraction': 0.7930277989353149, 'lambda_l1': 0.6666464500228022, 'lambda_l2': 2.985046541591548, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  18%|█▊        | 22/120 [30:01<2:13:20, 81.64s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:06:59,135] Trial 21 finished with value: -0.049054767029503364 and parameters: {'learning_rate': 0.03005628009499774, 'num_leaves': 235, 'max_depth': 8, 'min_data_in_leaf': 866, 'feature_fraction': 0.7319268462066069, 'bagging_fraction': 0.6068906381786102, 'lambda_l1': 2.6949829944169936, 'lambda_l2': 0.45023110267188504, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  19%|█▉        | 23/120 [30:19<1:41:07, 62.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:07:17,169] Trial 22 finished with value: -0.047160012250797655 and parameters: {'learning_rate': 0.02809436190279661, 'num_leaves': 216, 'max_depth': 6, 'min_data_in_leaf': 950, 'feature_fraction': 0.7298141242634963, 'bagging_fraction': 0.6058818626838158, 'lambda_l1': 2.8366926485638446, 'lambda_l2': 1.1016646269559356, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  20%|██        | 24/120 [30:43<1:21:45, 51.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:07:41,548] Trial 23 finished with value: -0.05057078732852799 and parameters: {'learning_rate': 0.09262335874147123, 'num_leaves': 400, 'max_depth': 7, 'min_data_in_leaf': 410, 'feature_fraction': 0.6448527127962934, 'bagging_fraction': 0.7012570475887573, 'lambda_l1': 4.292581287576205, 'lambda_l2': 0.012397327052607786, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  21%|██        | 25/120 [31:07<1:07:49, 42.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:08:05,125] Trial 24 finished with value: -0.0473592911018062 and parameters: {'learning_rate': 0.09087187675497409, 'num_leaves': 964, 'max_depth': 7, 'min_data_in_leaf': 386, 'feature_fraction': 0.6314667702813612, 'bagging_fraction': 0.701437289919039, 'lambda_l1': 4.625856602460901, 'lambda_l2': 1.480059347716286, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  22%|██▏       | 26/120 [31:26<55:42, 35.56s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:08:23,686] Trial 25 finished with value: -0.04554325449907609 and parameters: {'learning_rate': 0.06917745399795901, 'num_leaves': 402, 'max_depth': 6, 'min_data_in_leaf': 175, 'feature_fraction': 0.6688776260862057, 'bagging_fraction': 0.7098563692368897, 'lambda_l1': 5.775032976203278, 'lambda_l2': 2.7524272909089533, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  22%|██▎       | 27/120 [37:39<3:32:03, 136.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:14:36,734] Trial 26 finished with value: -0.04536842742938305 and parameters: {'learning_rate': 0.13283571341925635, 'num_leaves': 112, 'max_depth': 9, 'min_data_in_leaf': 310, 'feature_fraction': 0.6192611360862433, 'bagging_fraction': 0.6529427160191681, 'lambda_l1': 8.53917965241267, 'lambda_l2': 0.09102136325245616, 'use_scale_pos_weight': True}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  23%|██▎       | 28/120 [38:02<2:37:41, 102.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:15:00,318] Trial 27 finished with value: -0.0488406728631523 and parameters: {'learning_rate': 0.09410453053916792, 'num_leaves': 381, 'max_depth': 7, 'min_data_in_leaf': 552, 'feature_fraction': 0.6559421831284565, 'bagging_fraction': 0.9243960637097927, 'lambda_l1': 4.686867286077171, 'lambda_l2': 2.249244482189138, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  24%|██▍       | 29/120 [38:23<1:58:31, 78.15s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:15:20,859] Trial 28 finished with value: -0.04521261942388336 and parameters: {'learning_rate': 0.05381677168523434, 'num_leaves': 785, 'max_depth': 6, 'min_data_in_leaf': 120, 'feature_fraction': 0.7003727046638515, 'bagging_fraction': 0.7901516680363412, 'lambda_l1': 3.8827729720445583, 'lambda_l2': 3.674912837086878, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  25%|██▌       | 30/120 [39:00<1:38:43, 65.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:15:57,894] Trial 29 finished with value: -0.048751378467377926 and parameters: {'learning_rate': 0.05588543609872914, 'num_leaves': 152, 'max_depth': 10, 'min_data_in_leaf': 489, 'feature_fraction': 0.6266973597676178, 'bagging_fraction': 0.8656719423746208, 'lambda_l1': 6.032435944081324, 'lambda_l2': 0.8816371192232308, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  26%|██▌       | 31/120 [39:29<1:21:17, 54.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:16:27,014] Trial 30 finished with value: -0.047646110795301226 and parameters: {'learning_rate': 0.07264835519765214, 'num_leaves': 101, 'max_depth': 8, 'min_data_in_leaf': 213, 'feature_fraction': 0.6412409583286119, 'bagging_fraction': 0.722589840572732, 'lambda_l1': 7.992372690469031, 'lambda_l2': 0.6389882576350727, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  27%|██▋       | 32/120 [39:58<1:09:17, 47.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:16:56,595] Trial 31 finished with value: -0.04924010022270428 and parameters: {'learning_rate': 0.03671520715986933, 'num_leaves': 219, 'max_depth': 8, 'min_data_in_leaf': 640, 'feature_fraction': 0.7202484589048174, 'bagging_fraction': 0.641634472204889, 'lambda_l1': 2.42705255647377, 'lambda_l2': 0.3054311150310476, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  28%|██▊       | 33/120 [40:21<57:43, 39.82s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:17:19,091] Trial 32 finished with value: -0.04993667705040755 and parameters: {'learning_rate': 0.09498912500204774, 'num_leaves': 268, 'max_depth': 7, 'min_data_in_leaf': 1033, 'feature_fraction': 0.6718379398320271, 'bagging_fraction': 0.6851558810421741, 'lambda_l1': 3.814091798284676, 'lambda_l2': 0.004496969254502825, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  28%|██▊       | 34/120 [40:45<50:11, 35.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:17:42,920] Trial 33 finished with value: -0.04746837395349835 and parameters: {'learning_rate': 0.09453213247208832, 'num_leaves': 572, 'max_depth': 7, 'min_data_in_leaf': 457, 'feature_fraction': 0.6674505227809395, 'bagging_fraction': 0.6881611556297006, 'lambda_l1': 3.9658192611189573, 'lambda_l2': 1.1467918671226025, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  29%|██▉       | 35/120 [41:07<44:16, 31.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:18:05,396] Trial 34 finished with value: -0.04757789487963484 and parameters: {'learning_rate': 0.12925242254894442, 'num_leaves': 347, 'max_depth': 7, 'min_data_in_leaf': 1100, 'feature_fraction': 0.7479639126899681, 'bagging_fraction': 0.6634000829605002, 'lambda_l1': 3.411052694659261, 'lambda_l2': 1.3626685478614995, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  30%|███       | 36/120 [48:50<3:44:56, 160.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:25:48,050] Trial 35 finished with value: -0.0456974166550439 and parameters: {'learning_rate': 0.158154023387919, 'num_leaves': 137, 'max_depth': 6, 'min_data_in_leaf': 2593, 'feature_fraction': 0.6159695771662378, 'bagging_fraction': 0.7570082862548438, 'lambda_l1': 4.796007543267684, 'lambda_l2': 0.6903498836382649, 'use_scale_pos_weight': True}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  31%|███       | 37/120 [49:20<2:48:16, 121.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:26:18,615] Trial 36 finished with value: -0.04829785895692207 and parameters: {'learning_rate': 0.10127444100324538, 'num_leaves': 187, 'max_depth': 9, 'min_data_in_leaf': 322, 'feature_fraction': 0.6727544552452763, 'bagging_fraction': 0.9437708029638056, 'lambda_l1': 5.165309783395328, 'lambda_l2': 1.9604112772527902, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  32%|███▏      | 38/120 [49:39<2:03:56, 90.69s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:26:37,091] Trial 37 finished with value: -0.048906554345140914 and parameters: {'learning_rate': 0.0827123592969709, 'num_leaves': 279, 'max_depth': 7, 'min_data_in_leaf': 1392, 'feature_fraction': 0.7799196609798072, 'bagging_fraction': 0.6810937763535648, 'lambda_l1': 4.10123105390894, 'lambda_l2': 0.5898015505892658, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  32%|███▎      | 39/120 [53:09<2:50:35, 126.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:30:06,692] Trial 38 finished with value: -0.04674999556432984 and parameters: {'learning_rate': 0.17810375562295905, 'num_leaves': 442, 'max_depth': 12, 'min_data_in_leaf': 659, 'feature_fraction': 0.7002923160576785, 'bagging_fraction': 0.8306833777894, 'lambda_l1': 3.321856968071143, 'lambda_l2': 2.2830699836290016, 'use_scale_pos_weight': True}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  33%|███▎      | 40/120 [53:24<2:03:55, 92.94s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:30:21,651] Trial 39 finished with value: -0.04359988790537431 and parameters: {'learning_rate': 0.11230116813062149, 'num_leaves': 33, 'max_depth': 9, 'min_data_in_leaf': 102, 'feature_fraction': 0.6376946067616247, 'bagging_fraction': 0.870944442701136, 'lambda_l1': 6.444532935672869, 'lambda_l2': 8.63916955451431, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  34%|███▍      | 41/120 [58:10<3:18:52, 151.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:35:08,282] Trial 40 finished with value: -0.045091318758749076 and parameters: {'learning_rate': 0.14278632093531834, 'num_leaves': 89, 'max_depth': 10, 'min_data_in_leaf': 390, 'feature_fraction': 0.8806232670378836, 'bagging_fraction': 0.6326319195383978, 'lambda_l1': 1.92531082151908, 'lambda_l2': 9.921404257692, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  35%|███▌      | 42/120 [58:34<2:26:46, 112.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:35:32,199] Trial 41 finished with value: -0.04904847098850199 and parameters: {'learning_rate': 0.06540534589086827, 'num_leaves': 271, 'max_depth': 8, 'min_data_in_leaf': 951, 'feature_fraction': 0.7596602141148018, 'bagging_fraction': 0.6256179439329138, 'lambda_l1': 2.2414922684536864, 'lambda_l2': 0.01582214181372178, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  36%|███▌      | 43/120 [58:54<1:49:10, 85.08s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:35:52,332] Trial 42 finished with value: -0.049785749754185 and parameters: {'learning_rate': 0.07824665749925631, 'num_leaves': 520, 'max_depth': 7, 'min_data_in_leaf': 771, 'feature_fraction': 0.7123108945387185, 'bagging_fraction': 0.6993725887638069, 'lambda_l1': 1.3279799102445624, 'lambda_l2': 0.07921879660110953, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  37%|███▋      | 44/120 [59:14<1:23:07, 65.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:36:12,578] Trial 43 finished with value: -0.04776279741720268 and parameters: {'learning_rate': 0.07930305222449491, 'num_leaves': 701, 'max_depth': 7, 'min_data_in_leaf': 631, 'feature_fraction': 0.656538859082549, 'bagging_fraction': 0.7045128246597981, 'lambda_l1': 0.7646349988176973, 'lambda_l2': 1.0844017821987888, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  38%|███▊      | 45/120 [59:32<1:04:00, 51.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:36:30,137] Trial 44 finished with value: -0.04896705285663414 and parameters: {'learning_rate': 0.09128451267680836, 'num_leaves': 527, 'max_depth': 6, 'min_data_in_leaf': 1598, 'feature_fraction': 0.6030574538557691, 'bagging_fraction': 0.7430023511378312, 'lambda_l1': 1.1983117927609737, 'lambda_l2': 0.5802110742062296, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  38%|███▊      | 46/120 [1:00:17<1:01:01, 49.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:37:15,609] Trial 45 finished with value: -0.04693075003114313 and parameters: {'learning_rate': 0.1018172006228713, 'num_leaves': 358, 'max_depth': 14, 'min_data_in_leaf': 1092, 'feature_fraction': 0.7037617820467316, 'bagging_fraction': 0.7162330339898231, 'lambda_l1': 5.3679566726857795, 'lambda_l2': 1.485239129891643, 'use_scale_pos_weight': True}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  39%|███▉      | 47/120 [1:00:36<48:52, 40.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:37:34,052] Trial 46 finished with value: -0.044874797570533254 and parameters: {'learning_rate': 0.075074103022397, 'num_leaves': 594, 'max_depth': 7, 'min_data_in_leaf': 2183, 'feature_fraction': 0.6796068812780721, 'bagging_fraction': 0.77986012475285, 'lambda_l1': 3.183686697541985, 'lambda_l2': 5.166585727029952, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  40%|████      | 48/120 [1:00:53<39:50, 33.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:37:50,963] Trial 47 finished with value: -0.04389900747636605 and parameters: {'learning_rate': 0.11971093337213208, 'num_leaves': 193, 'max_depth': 6, 'min_data_in_leaf': 745, 'feature_fraction': 0.9958724338772456, 'bagging_fraction': 0.6670276277642574, 'lambda_l1': 7.2518387517171075, 'lambda_l2': 5.771315908058693, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  41%|████      | 49/120 [1:01:10<33:26, 28.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:38:07,709] Trial 48 finished with value: -0.04503878174828197 and parameters: {'learning_rate': 0.08592246646020775, 'num_leaves': 478, 'max_depth': 6, 'min_data_in_leaf': 131, 'feature_fraction': 0.8099395317806294, 'bagging_fraction': 0.7449603615192827, 'lambda_l1': 4.3666771065017, 'lambda_l2': 4.567919317659721, 'use_scale_pos_weight': False}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  42%|████▏     | 50/120 [1:01:36<32:20, 27.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:38:34,150] Trial 49 finished with value: -0.05028805109696405 and parameters: {'learning_rate': 0.051782154531793245, 'num_leaves': 159, 'max_depth': 8, 'min_data_in_leaf': 478, 'feature_fraction': 0.9476682970843022, 'bagging_fraction': 0.8171438228283645, 'lambda_l1': 1.4540975020518785, 'lambda_l2': 0.3260497582493277, 'use_scale_pos_weight': True}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0507574:  42%|████▎     | 51/120 [1:02:03<31:46, 27.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:39:01,566] Trial 50 finished with value: -0.049252647030165415 and parameters: {'learning_rate': 0.04819837464295326, 'num_leaves': 129, 'max_depth': 8, 'min_data_in_leaf': 448, 'feature_fraction': 0.9465595824263221, 'bagging_fraction': 0.8547752132501423, 'lambda_l1': 6.067659361761516, 'lambda_l2': 0.48284311659695867, 'use_scale_pos_weight': True}. Best is trial 13 with value: -0.05075738128694907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 51. Best value: -0.0508573:  43%|████▎     | 52/120 [1:02:27<29:45, 26.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:39:24,620] Trial 51 finished with value: -0.05085730481395051 and parameters: {'learning_rate': 0.0642129265192633, 'num_leaves': 163, 'max_depth': 7, 'min_data_in_leaf': 349, 'feature_fraction': 0.8460764727180428, 'bagging_fraction': 0.8084434093629397, 'lambda_l1': 1.603806127347788, 'lambda_l2': 0.08097757563341035, 'use_scale_pos_weight': True}. Best is trial 51 with value: -0.05085730481395051.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 51. Best value: -0.0508573:  44%|████▍     | 53/120 [1:02:50<28:29, 25.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:39:48,404] Trial 52 finished with value: -0.048998490657716186 and parameters: {'learning_rate': 0.04230392239529087, 'num_leaves': 171, 'max_depth': 7, 'min_data_in_leaf': 258, 'feature_fraction': 0.9316322816997807, 'bagging_fraction': 0.8030820430603333, 'lambda_l1': 0.16925291724917613, 'lambda_l2': 0.8933886200250383, 'use_scale_pos_weight': True}. Best is trial 51 with value: -0.05085730481395051.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 51. Best value: -0.0508573:  45%|████▌     | 54/120 [1:03:08<25:36, 23.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:40:06,493] Trial 53 finished with value: -0.05028386572059557 and parameters: {'learning_rate': 0.05057382126408224, 'num_leaves': 154, 'max_depth': 6, 'min_data_in_leaf': 358, 'feature_fraction': 0.9118675174301336, 'bagging_fraction': 0.9532905730586811, 'lambda_l1': 1.6625981182625154, 'lambda_l2': 0.3993557476765375, 'use_scale_pos_weight': True}. Best is trial 51 with value: -0.05085730481395051.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 51. Best value: -0.0508573:  46%|████▌     | 55/120 [1:03:26<23:18, 21.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:40:23,868] Trial 54 finished with value: -0.048972067801428355 and parameters: {'learning_rate': 0.051608986086776956, 'num_leaves': 155, 'max_depth': 6, 'min_data_in_leaf': 204, 'feature_fraction': 0.8579832412032702, 'bagging_fraction': 0.9592516571529648, 'lambda_l1': 1.450898997330125, 'lambda_l2': 1.357698999199393, 'use_scale_pos_weight': True}. Best is trial 51 with value: -0.05085730481395051.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 51. Best value: -0.0508573:  47%|████▋     | 56/120 [1:03:43<21:38, 20.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:40:41,300] Trial 55 finished with value: -0.04987019967874462 and parameters: {'learning_rate': 0.061465717145498984, 'num_leaves': 75, 'max_depth': 6, 'min_data_in_leaf': 350, 'feature_fraction': 0.9357825081343162, 'bagging_fraction': 0.8877717308561366, 'lambda_l1': 1.7878179168185728, 'lambda_l2': 0.4038015646147412, 'use_scale_pos_weight': True}. Best is trial 51 with value: -0.05085730481395051.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 51. Best value: -0.0508573:  48%|████▊     | 57/120 [1:04:01<20:40, 19.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:40:59,603] Trial 56 finished with value: -0.04482380530921467 and parameters: {'learning_rate': 0.03941678837380844, 'num_leaves': 61, 'max_depth': 6, 'min_data_in_leaf': 262, 'feature_fraction': 0.9646405155168699, 'bagging_fraction': 0.9807596620335117, 'lambda_l1': 0.7139268621182145, 'lambda_l2': 6.743751382951948, 'use_scale_pos_weight': True}. Best is trial 51 with value: -0.05085730481395051.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 51. Best value: -0.0508573:  48%|████▊     | 58/120 [1:04:26<21:42, 21.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:41:23,687] Trial 57 finished with value: -0.045552106148541584 and parameters: {'learning_rate': 0.0490961208654586, 'num_leaves': 100, 'max_depth': 8, 'min_data_in_leaf': 538, 'feature_fraction': 0.9068401508283027, 'bagging_fraction': 0.8179664898629301, 'lambda_l1': 2.955750916912221, 'lambda_l2': 3.4931706647299117, 'use_scale_pos_weight': True}. Best is trial 51 with value: -0.05085730481395051.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 51. Best value: -0.0508573:  49%|████▉     | 59/120 [1:04:43<20:23, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:41:41,506] Trial 58 finished with value: -0.048769321844449966 and parameters: {'learning_rate': 0.060105247672035685, 'num_leaves': 122, 'max_depth': 6, 'min_data_in_leaf': 353, 'feature_fraction': 0.8580008627807625, 'bagging_fraction': 0.9401065781338336, 'lambda_l1': 2.0739054460810395, 'lambda_l2': 1.6195956955933866, 'use_scale_pos_weight': True}. Best is trial 51 with value: -0.05085730481395051.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 51. Best value: -0.0508573:  50%|█████     | 60/120 [1:05:05<20:32, 20.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:42:03,172] Trial 59 finished with value: -0.048787099978536135 and parameters: {'learning_rate': 0.06595426092184975, 'num_leaves': 200, 'max_depth': 7, 'min_data_in_leaf': 293, 'feature_fraction': 0.9694350964589968, 'bagging_fraction': 0.8463483244786976, 'lambda_l1': 1.5480016247026076, 'lambda_l2': 2.131269015547951, 'use_scale_pos_weight': True}. Best is trial 51 with value: -0.05085730481395051.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 51. Best value: -0.0508573:  51%|█████     | 61/120 [1:05:23<19:20, 19.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:42:20,795] Trial 60 finished with value: -0.049049500495148425 and parameters: {'learning_rate': 0.03700536213978513, 'num_leaves': 167, 'max_depth': 6, 'min_data_in_leaf': 185, 'feature_fraction': 0.9119029954902986, 'bagging_fraction': 0.897452430488695, 'lambda_l1': 9.478871177889957, 'lambda_l2': 0.9852063443152573, 'use_scale_pos_weight': True}. Best is trial 51 with value: -0.05085730481395051.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  52%|█████▏    | 62/120 [1:05:45<19:48, 20.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:42:43,242] Trial 61 finished with value: -0.051400096366481546 and parameters: {'learning_rate': 0.10882923528329398, 'num_leaves': 261, 'max_depth': 7, 'min_data_in_leaf': 417, 'feature_fraction': 0.8506023138853029, 'bagging_fraction': 0.8086202834324894, 'lambda_l1': 0.9266777316963086, 'lambda_l2': 0.016826855884411945, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  52%|█████▎    | 63/120 [1:06:09<20:21, 21.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:43:06,862] Trial 62 finished with value: -0.051114930168948226 and parameters: {'learning_rate': 0.10499450579229824, 'num_leaves': 142, 'max_depth': 7, 'min_data_in_leaf': 454, 'feature_fraction': 0.8409943991283577, 'bagging_fraction': 0.8147853401979317, 'lambda_l1': 1.077937527880003, 'lambda_l2': 0.31135082744664033, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  53%|█████▎    | 64/120 [1:06:37<21:57, 23.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:43:35,255] Trial 63 finished with value: -0.049151600207492076 and parameters: {'learning_rate': 0.1118199819886132, 'num_leaves': 142, 'max_depth': 8, 'min_data_in_leaf': 421, 'feature_fraction': 0.844641535721853, 'bagging_fraction': 0.8137028118202829, 'lambda_l1': 1.116106023652056, 'lambda_l2': 0.25393048199064183, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  54%|█████▍    | 65/120 [1:06:58<20:53, 22.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:43:56,369] Trial 64 finished with value: -0.049284792566772706 and parameters: {'learning_rate': 0.1299675723239964, 'num_leaves': 208, 'max_depth': 7, 'min_data_in_leaf': 488, 'feature_fraction': 0.8081173853734988, 'bagging_fraction': 0.8074936734956368, 'lambda_l1': 0.5557429822548742, 'lambda_l2': 0.8625942807845518, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  55%|█████▌    | 66/120 [1:07:24<21:11, 23.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:44:21,658] Trial 65 finished with value: -0.048411829540228934 and parameters: {'learning_rate': 0.10562646898494947, 'num_leaves': 246, 'max_depth': 8, 'min_data_in_leaf': 596, 'feature_fraction': 0.8276832899871199, 'bagging_fraction': 0.7843274968607037, 'lambda_l1': 0.25547494054136655, 'lambda_l2': 1.173036762474548, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  56%|█████▌    | 67/120 [1:07:46<20:23, 23.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:44:43,653] Trial 66 finished with value: -0.0497155713213992 and parameters: {'learning_rate': 0.0865954197120276, 'num_leaves': 117, 'max_depth': 7, 'min_data_in_leaf': 509, 'feature_fraction': 0.8730817698511008, 'bagging_fraction': 0.7703483926174083, 'lambda_l1': 1.1584650406134824, 'lambda_l2': 0.7078680774032725, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  57%|█████▋    | 68/120 [1:12:20<1:25:29, 98.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:49:18,592] Trial 67 finished with value: -0.04513052540907314 and parameters: {'learning_rate': 0.1443036473638373, 'num_leaves': 314, 'max_depth': 7, 'min_data_in_leaf': 422, 'feature_fraction': 0.7954886686520972, 'bagging_fraction': 0.8266772234556403, 'lambda_l1': 0.866942142641669, 'lambda_l2': 0.38775454010448096, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  57%|█████▊    | 69/120 [1:12:48<1:05:44, 77.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:49:46,260] Trial 68 finished with value: -0.05003033410542288 and parameters: {'learning_rate': 0.06969189779129677, 'num_leaves': 174, 'max_depth': 8, 'min_data_in_leaf': 278, 'feature_fraction': 0.8417179250960062, 'bagging_fraction': 0.8364415359744617, 'lambda_l1': 7.8207721310806555, 'lambda_l2': 0.02094392944410814, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  58%|█████▊    | 70/120 [1:13:12<51:05, 61.30s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:50:10,126] Trial 69 finished with value: -0.0469848001070266 and parameters: {'learning_rate': 0.09874463851533356, 'num_leaves': 90, 'max_depth': 9, 'min_data_in_leaf': 228, 'feature_fraction': 0.8186303275634232, 'bagging_fraction': 0.7568019033934609, 'lambda_l1': 2.2707486710071203, 'lambda_l2': 0.6872172050826946, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  59%|█████▉    | 71/120 [1:13:35<40:38, 49.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:50:32,945] Trial 70 finished with value: -0.049698034030857284 and parameters: {'learning_rate': 0.11972046283164928, 'num_leaves': 134, 'max_depth': 7, 'min_data_in_leaf': 338, 'feature_fraction': 0.894273127025356, 'bagging_fraction': 0.7299656564114169, 'lambda_l1': 4.426300554702608, 'lambda_l2': 0.2432035347241976, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  60%|██████    | 72/120 [1:13:52<32:06, 40.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:50:50,607] Trial 71 finished with value: -0.04978885578499487 and parameters: {'learning_rate': 0.05547764347358277, 'num_leaves': 148, 'max_depth': 6, 'min_data_in_leaf': 397, 'feature_fraction': 0.8609462622772968, 'bagging_fraction': 0.7970751542587431, 'lambda_l1': 1.6868543173298987, 'lambda_l2': 0.34874725181010924, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  61%|██████    | 73/120 [1:14:10<26:09, 33.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:51:08,320] Trial 72 finished with value: -0.04950261199130882 and parameters: {'learning_rate': 0.04463403489476341, 'num_leaves': 222, 'max_depth': 6, 'min_data_in_leaf': 364, 'feature_fraction': 0.9161201112359517, 'bagging_fraction': 0.9978838372597358, 'lambda_l1': 0.42265207553197626, 'lambda_l2': 1.2201413202178726, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  62%|██████▏   | 74/120 [1:14:32<22:54, 29.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:51:30,007] Trial 73 finished with value: -0.050911301184586616 and parameters: {'learning_rate': 0.10887870862990262, 'num_leaves': 166, 'max_depth': 7, 'min_data_in_leaf': 463, 'feature_fraction': 0.6168472639010866, 'bagging_fraction': 0.8709945279661944, 'lambda_l1': 0.9475788022177417, 'lambda_l2': 0.3861177378359155, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  62%|██████▎   | 75/120 [1:14:54<20:41, 27.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:51:52,205] Trial 74 finished with value: -0.04905527402835835 and parameters: {'learning_rate': 0.1279168331119968, 'num_leaves': 249, 'max_depth': 7, 'min_data_in_leaf': 468, 'feature_fraction': 0.6229045628713559, 'bagging_fraction': 0.8803857250348968, 'lambda_l1': 1.0001777995797312, 'lambda_l2': 1.7091065563611403, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  63%|██████▎   | 76/120 [1:15:17<19:10, 26.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:52:15,008] Trial 75 finished with value: -0.04962152981706152 and parameters: {'learning_rate': 0.1105123831239292, 'num_leaves': 106, 'max_depth': 7, 'min_data_in_leaf': 562, 'feature_fraction': 0.6116280120710511, 'bagging_fraction': 0.9191131698209005, 'lambda_l1': 2.5317427965977046, 'lambda_l2': 0.8514753508143693, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  64%|██████▍   | 77/120 [1:19:49<1:11:36, 99.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:56:47,018] Trial 76 finished with value: -0.04760455097757842 and parameters: {'learning_rate': 0.15324471819900626, 'num_leaves': 192, 'max_depth': 8, 'min_data_in_leaf': 708, 'feature_fraction': 0.6434062708761442, 'bagging_fraction': 0.8459808096190813, 'lambda_l1': 0.00746176338743787, 'lambda_l2': 9.070650457145128, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  65%|██████▌   | 78/120 [1:20:23<56:03, 80.07s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:57:20,818] Trial 77 finished with value: -0.049121452821592505 and parameters: {'learning_rate': 0.0900516782049472, 'num_leaves': 159, 'max_depth': 12, 'min_data_in_leaf': 312, 'feature_fraction': 0.838701269336011, 'bagging_fraction': 0.8641397067138312, 'lambda_l1': 6.797523986955302, 'lambda_l2': 0.24963448262992743, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  66%|██████▌   | 79/120 [1:20:43<42:31, 62.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:57:41,414] Trial 78 finished with value: -0.050019836303064856 and parameters: {'learning_rate': 0.09857084215873213, 'num_leaves': 300, 'max_depth': 7, 'min_data_in_leaf': 818, 'feature_fraction': 0.6297980390858297, 'bagging_fraction': 0.7786630752315008, 'lambda_l1': 0.3714746521041681, 'lambda_l2': 0.6214398519271591, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  67%|██████▋   | 80/120 [1:21:04<33:08, 49.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:58:01,897] Trial 79 finished with value: -0.04823519496997242 and parameters: {'learning_rate': 0.11680286360193969, 'num_leaves': 178, 'max_depth': 7, 'min_data_in_leaf': 638, 'feature_fraction': 0.6562935559379066, 'bagging_fraction': 0.8162756675569587, 'lambda_l1': 3.6245424367423915, 'lambda_l2': 2.457062190544512, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  68%|██████▊   | 81/120 [1:21:30<27:42, 42.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:58:28,026] Trial 80 finished with value: -0.048879632348162484 and parameters: {'learning_rate': 0.1075860040365248, 'num_leaves': 130, 'max_depth': 8, 'min_data_in_leaf': 517, 'feature_fraction': 0.6112284700574672, 'bagging_fraction': 0.8510163324119142, 'lambda_l1': 1.4312336891427222, 'lambda_l2': 1.0180187835058043, 'use_scale_pos_weight': False}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  68%|██████▊   | 82/120 [1:21:46<22:02, 34.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:58:44,563] Trial 81 finished with value: -0.05089291094127633 and parameters: {'learning_rate': 0.1241279720264084, 'num_leaves': 154, 'max_depth': 6, 'min_data_in_leaf': 434, 'feature_fraction': 0.9588405152369379, 'bagging_fraction': 0.9349659862216734, 'lambda_l1': 2.0234931185038296, 'lambda_l2': 0.0009633589642664038, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  69%|██████▉   | 83/120 [1:22:03<18:06, 29.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 15:59:01,216] Trial 82 finished with value: -0.05104528987037704 and parameters: {'learning_rate': 0.12424030360565742, 'num_leaves': 208, 'max_depth': 6, 'min_data_in_leaf': 431, 'feature_fraction': 0.9719773801097159, 'bagging_fraction': 0.9252947245763466, 'lambda_l1': 0.9178230966642902, 'lambda_l2': 0.02276138825480702, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  70%|███████   | 84/120 [1:28:04<1:17:16, 128.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:05:02,036] Trial 83 finished with value: -0.04582561369975257 and parameters: {'learning_rate': 0.13675695168834415, 'num_leaves': 217, 'max_depth': 6, 'min_data_in_leaf': 385, 'feature_fraction': 0.9786143873211253, 'bagging_fraction': 0.9332957398804212, 'lambda_l1': 1.9259820049547611, 'lambda_l2': 0.02694323359339254, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  71%|███████   | 85/120 [1:32:59<1:44:10, 178.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:09:56,778] Trial 84 finished with value: -0.04449464067750491 and parameters: {'learning_rate': 0.17403127467951227, 'num_leaves': 184, 'max_depth': 6, 'min_data_in_leaf': 560, 'feature_fraction': 0.9860667798092877, 'bagging_fraction': 0.903021305060445, 'lambda_l1': 0.7985747070764361, 'lambda_l2': 0.5566917794550419, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  72%|███████▏  | 86/120 [1:33:17<1:13:56, 130.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:10:15,048] Trial 85 finished with value: -0.05123961495136136 and parameters: {'learning_rate': 0.12621986969245177, 'num_leaves': 142, 'max_depth': 6, 'min_data_in_leaf': 438, 'feature_fraction': 0.7695329470778736, 'bagging_fraction': 0.962202266501355, 'lambda_l1': 2.9664089907742213, 'lambda_l2': 0.020805115658641016, 'use_scale_pos_weight': False}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  72%|███████▎  | 87/120 [1:33:35<53:10, 96.68s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:10:32,837] Trial 86 finished with value: -0.05094328096730406 and parameters: {'learning_rate': 0.1259849102302548, 'num_leaves': 140, 'max_depth': 6, 'min_data_in_leaf': 428, 'feature_fraction': 0.7818517971003209, 'bagging_fraction': 0.954685973752906, 'lambda_l1': 2.19576810755699, 'lambda_l2': 0.18036205812881392, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  73%|███████▎  | 88/120 [1:39:29<1:32:45, 173.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:16:26,998] Trial 87 finished with value: -0.04499548050042946 and parameters: {'learning_rate': 0.15109549240552161, 'num_leaves': 141, 'max_depth': 6, 'min_data_in_leaf': 447, 'feature_fraction': 0.7857181333494966, 'bagging_fraction': 0.9677969704257976, 'lambda_l1': 2.159257471267371, 'lambda_l2': 0.23224845827234386, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  74%|███████▍  | 89/120 [1:39:46<1:05:34, 126.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:16:44,219] Trial 88 finished with value: -0.04969575875694826 and parameters: {'learning_rate': 0.1267557753532692, 'num_leaves': 112, 'max_depth': 6, 'min_data_in_leaf': 328, 'feature_fraction': 0.7675645353214346, 'bagging_fraction': 0.9129866592675396, 'lambda_l1': 2.9036666277695247, 'lambda_l2': 0.8070730853541764, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  75%|███████▌  | 90/120 [1:44:23<1:25:54, 171.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:21:20,861] Trial 89 finished with value: -0.04384666220608679 and parameters: {'learning_rate': 0.19527252775273782, 'num_leaves': 125, 'max_depth': 6, 'min_data_in_leaf': 425, 'feature_fraction': 0.7479765667609959, 'bagging_fraction': 0.9308477458045971, 'lambda_l1': 2.3893439826269294, 'lambda_l2': 1.2978939564190504, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  76%|███████▌  | 91/120 [1:44:40<1:00:35, 125.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:21:37,772] Trial 90 finished with value: -0.050090126244400096 and parameters: {'learning_rate': 0.12408246360618905, 'num_leaves': 91, 'max_depth': 6, 'min_data_in_leaf': 600, 'feature_fraction': 0.7788398927615509, 'bagging_fraction': 0.9454602413657391, 'lambda_l1': 1.0652608700615898, 'lambda_l2': 0.4902767770769704, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  77%|███████▋  | 92/120 [1:49:37<1:22:38, 177.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:26:35,516] Trial 91 finished with value: -0.04583768518273076 and parameters: {'learning_rate': 0.13683325503748772, 'num_leaves': 164, 'max_depth': 7, 'min_data_in_leaf': 390, 'feature_fraction': 0.8065894285957796, 'bagging_fraction': 0.9756588782559432, 'lambda_l1': 2.728320223278096, 'lambda_l2': 0.03422535378780582, 'use_scale_pos_weight': False}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  78%|███████▊  | 93/120 [1:49:55<58:06, 129.12s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:26:52,744] Trial 92 finished with value: -0.050605441145238426 and parameters: {'learning_rate': 0.10464625915920124, 'num_leaves': 134, 'max_depth': 6, 'min_data_in_leaf': 450, 'feature_fraction': 0.8661504042929816, 'bagging_fraction': 0.9504389476681759, 'lambda_l1': 2.0254103406542567, 'lambda_l2': 0.19807905290087185, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  78%|███████▊  | 94/120 [1:55:04<1:19:20, 183.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:32:01,759] Trial 93 finished with value: -0.04552313222099314 and parameters: {'learning_rate': 0.16482658592797447, 'num_leaves': 141, 'max_depth': 6, 'min_data_in_leaf': 508, 'feature_fraction': 0.8655525302454188, 'bagging_fraction': 0.9656663698889104, 'lambda_l1': 1.667655946399869, 'lambda_l2': 0.23409962724464264, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  79%|███████▉  | 95/120 [1:55:20<55:28, 133.16s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:32:18,415] Trial 94 finished with value: -0.04931154955695672 and parameters: {'learning_rate': 0.12264931485506095, 'num_leaves': 204, 'max_depth': 6, 'min_data_in_leaf': 697, 'feature_fraction': 0.8480157034343412, 'bagging_fraction': 0.9237354589168429, 'lambda_l1': 2.031136713064665, 'lambda_l2': 0.6587970152061982, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  80%|████████  | 96/120 [1:55:37<39:19, 98.30s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:32:35,392] Trial 95 finished with value: -0.04973274744384882 and parameters: {'learning_rate': 0.11451226944222306, 'num_leaves': 111, 'max_depth': 6, 'min_data_in_leaf': 305, 'feature_fraction': 0.8264148256174182, 'bagging_fraction': 0.950136275676053, 'lambda_l1': 0.5623172661533894, 'lambda_l2': 0.9992192583776494, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  81%|████████  | 97/120 [1:55:54<28:16, 73.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:32:51,943] Trial 96 finished with value: -0.05056328443441354 and parameters: {'learning_rate': 0.10525686665589686, 'num_leaves': 97, 'max_depth': 6, 'min_data_in_leaf': 437, 'feature_fraction': 0.898914034282289, 'bagging_fraction': 0.9869740817380245, 'lambda_l1': 3.0642239828740747, 'lambda_l2': 0.47405972597270873, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  82%|████████▏ | 98/120 [1:56:16<21:21, 58.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:33:13,924] Trial 97 finished with value: -0.05135469607229836 and parameters: {'learning_rate': 0.1160036230161704, 'num_leaves': 121, 'max_depth': 7, 'min_data_in_leaf': 239, 'feature_fraction': 0.8175658069139526, 'bagging_fraction': 0.9593462239274491, 'lambda_l1': 1.355390780417659, 'lambda_l2': 0.23593437299371425, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  82%|████████▎ | 99/120 [1:56:41<16:55, 48.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:33:39,268] Trial 98 finished with value: -0.04921526318538778 and parameters: {'learning_rate': 0.020685122273955893, 'num_leaves': 235, 'max_depth': 7, 'min_data_in_leaf': 236, 'feature_fraction': 0.7942617076174121, 'bagging_fraction': 0.9382724368342323, 'lambda_l1': 1.3394563528312267, 'lambda_l2': 1.4399512149642877, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  83%|████████▎ | 100/120 [2:01:15<38:42, 116.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:38:13,495] Trial 99 finished with value: -0.04564544658941577 and parameters: {'learning_rate': 0.14588447960042342, 'num_leaves': 119, 'max_depth': 7, 'min_data_in_leaf': 376, 'feature_fraction': 0.7364177260846572, 'bagging_fraction': 0.9691869189259504, 'lambda_l1': 0.9335480449703903, 'lambda_l2': 0.8307790686527008, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  84%|████████▍ | 101/120 [2:06:00<52:46, 166.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:42:57,987] Trial 100 finished with value: -0.044987680054779496 and parameters: {'learning_rate': 0.13291379439785048, 'num_leaves': 182, 'max_depth': 7, 'min_data_in_leaf': 269, 'feature_fraction': 0.8492338886785927, 'bagging_fraction': 0.9589301554988184, 'lambda_l1': 1.7910602210088244, 'lambda_l2': 0.0012374123408660787, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  85%|████████▌ | 102/120 [2:06:16<36:27, 121.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:43:14,211] Trial 101 finished with value: -0.05111731957230933 and parameters: {'learning_rate': 0.11552893147012616, 'num_leaves': 149, 'max_depth': 6, 'min_data_in_leaf': 450, 'feature_fraction': 0.8186210338673836, 'bagging_fraction': 0.913775047000393, 'lambda_l1': 1.2810316090584635, 'lambda_l2': 0.2329879815051783, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: -0.0514001:  86%|████████▌ | 103/120 [2:06:33<25:31, 90.10s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:43:31,015] Trial 102 finished with value: -0.050170094981637485 and parameters: {'learning_rate': 0.11567173035773642, 'num_leaves': 166, 'max_depth': 6, 'min_data_in_leaf': 483, 'feature_fraction': 0.8037063190645218, 'bagging_fraction': 0.9304272968088166, 'lambda_l1': 1.2638664897289082, 'lambda_l2': 0.4733766097873819, 'use_scale_pos_weight': True}. Best is trial 61 with value: -0.051400096366481546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 103. Best value: -0.0514761:  87%|████████▋ | 104/120 [2:06:50<18:10, 68.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:43:47,921] Trial 103 finished with value: -0.051476061027520226 and parameters: {'learning_rate': 0.09676187293344114, 'num_leaves': 149, 'max_depth': 6, 'min_data_in_leaf': 337, 'feature_fraction': 0.817208332958476, 'bagging_fraction': 0.8915744579968162, 'lambda_l1': 0.6047067104584021, 'lambda_l2': 0.23123264102704758, 'use_scale_pos_weight': True}. Best is trial 103 with value: -0.051476061027520226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 103. Best value: -0.0514761:  88%|████████▊ | 105/120 [2:11:13<31:38, 126.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:48:10,824] Trial 104 finished with value: -0.04508666995971659 and parameters: {'learning_rate': 0.13658434849293943, 'num_leaves': 148, 'max_depth': 7, 'min_data_in_leaf': 282, 'feature_fraction': 0.8167328113474106, 'bagging_fraction': 0.8932385604949165, 'lambda_l1': 0.5052313453962465, 'lambda_l2': 0.22895872730211952, 'use_scale_pos_weight': True}. Best is trial 103 with value: -0.051476061027520226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 103. Best value: -0.0514761:  88%|████████▊ | 106/120 [2:11:33<22:06, 94.73s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:48:31,264] Trial 105 finished with value: -0.049421742768758326 and parameters: {'learning_rate': 0.10074921526382194, 'num_leaves': 131, 'max_depth': 7, 'min_data_in_leaf': 343, 'feature_fraction': 0.8339759753040463, 'bagging_fraction': 0.9101726505842762, 'lambda_l1': 0.710898922405383, 'lambda_l2': 0.7122424233864169, 'use_scale_pos_weight': True}. Best is trial 103 with value: -0.051476061027520226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 103. Best value: -0.0514761:  89%|████████▉ | 107/120 [2:11:50<15:26, 71.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:48:47,698] Trial 106 finished with value: -0.04956904300442117 and parameters: {'learning_rate': 0.12113349652660284, 'num_leaves': 145, 'max_depth': 6, 'min_data_in_leaf': 312, 'feature_fraction': 0.8123281693256643, 'bagging_fraction': 0.8813706076782963, 'lambda_l1': 0.2722444902652338, 'lambda_l2': 1.0678776157662075, 'use_scale_pos_weight': True}. Best is trial 103 with value: -0.051476061027520226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 103. Best value: -0.0514761:  90%|█████████ | 108/120 [2:12:06<10:57, 54.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:49:04,210] Trial 107 finished with value: -0.05088222980067314 and parameters: {'learning_rate': 0.09738140773471674, 'num_leaves': 198, 'max_depth': 6, 'min_data_in_leaf': 365, 'feature_fraction': 0.8210161826966841, 'bagging_fraction': 0.9226974383109627, 'lambda_l1': 1.5451375840922184, 'lambda_l2': 0.41985379315344695, 'use_scale_pos_weight': True}. Best is trial 103 with value: -0.051476061027520226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 103. Best value: -0.0514761:  91%|█████████ | 109/120 [2:12:23<07:56, 43.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:49:20,764] Trial 108 finished with value: -0.05081990665667136 and parameters: {'learning_rate': 0.0967288337573648, 'num_leaves': 258, 'max_depth': 6, 'min_data_in_leaf': 248, 'feature_fraction': 0.799161141098963, 'bagging_fraction': 0.9009080761010164, 'lambda_l1': 1.0217225185515677, 'lambda_l2': 0.42782197257319304, 'use_scale_pos_weight': True}. Best is trial 103 with value: -0.051476061027520226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 103. Best value: -0.0514761:  92%|█████████▏| 110/120 [2:12:39<05:52, 35.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:49:37,128] Trial 109 finished with value: -0.050095822376020956 and parameters: {'learning_rate': 0.10986006843044502, 'num_leaves': 200, 'max_depth': 6, 'min_data_in_leaf': 416, 'feature_fraction': 0.8202035521925042, 'bagging_fraction': 0.9243701961158481, 'lambda_l1': 1.2625252628724084, 'lambda_l2': 0.5554440530901432, 'use_scale_pos_weight': True}. Best is trial 103 with value: -0.051476061027520226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 103. Best value: -0.0514761:  92%|█████████▎| 111/120 [2:16:49<14:57, 99.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:53:47,393] Trial 110 finished with value: -0.04945411538033576 and parameters: {'learning_rate': 0.11655831829257973, 'num_leaves': 230, 'max_depth': 14, 'min_data_in_leaf': 538, 'feature_fraction': 0.7845379925919708, 'bagging_fraction': 0.9106657449635028, 'lambda_l1': 1.5002809890196624, 'lambda_l2': 0.24957216654386546, 'use_scale_pos_weight': True}. Best is trial 103 with value: -0.051476061027520226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 103. Best value: -0.0514761:  93%|█████████▎| 112/120 [2:17:05<09:56, 74.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:54:03,335] Trial 111 finished with value: -0.051188431492213436 and parameters: {'learning_rate': 0.12485763070385068, 'num_leaves': 158, 'max_depth': 6, 'min_data_in_leaf': 370, 'feature_fraction': 0.8349080153194082, 'bagging_fraction': 0.956685085725817, 'lambda_l1': 0.864355107490251, 'lambda_l2': 0.16795948297459748, 'use_scale_pos_weight': True}. Best is trial 103 with value: -0.051476061027520226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 103. Best value: -0.0514761:  94%|█████████▍| 113/120 [2:17:22<06:40, 57.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:54:19,887] Trial 112 finished with value: -0.04993616990140696 and parameters: {'learning_rate': 0.12462529337623159, 'num_leaves': 153, 'max_depth': 6, 'min_data_in_leaf': 164, 'feature_fraction': 0.7736328191443076, 'bagging_fraction': 0.936278344887348, 'lambda_l1': 0.8573581922471687, 'lambda_l2': 0.7944676156943066, 'use_scale_pos_weight': True}. Best is trial 103 with value: -0.051476061027520226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 103. Best value: -0.0514761:  95%|█████████▌| 114/120 [2:17:38<04:29, 44.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:54:35,973] Trial 113 finished with value: -0.05136012335499579 and parameters: {'learning_rate': 0.10901110101141388, 'num_leaves': 179, 'max_depth': 6, 'min_data_in_leaf': 371, 'feature_fraction': 0.831894345729742, 'bagging_fraction': 0.9868296449073949, 'lambda_l1': 0.5983487041008684, 'lambda_l2': 0.3851524082067498, 'use_scale_pos_weight': True}. Best is trial 103 with value: -0.051476061027520226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 103. Best value: -0.0514761:  96%|█████████▌| 115/120 [2:17:54<03:00, 36.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:54:51,884] Trial 114 finished with value: -0.05146262092429018 and parameters: {'learning_rate': 0.11047500940065634, 'num_leaves': 175, 'max_depth': 6, 'min_data_in_leaf': 397, 'feature_fraction': 0.8300572347659944, 'bagging_fraction': 0.9926682056666731, 'lambda_l1': 0.6826539075075009, 'lambda_l2': 0.14893605753778505, 'use_scale_pos_weight': True}. Best is trial 103 with value: -0.051476061027520226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 103. Best value: -0.0514761:  97%|█████████▋| 116/120 [2:18:26<02:20, 35.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:55:24,307] Trial 115 finished with value: -0.04598625361443869 and parameters: {'learning_rate': 0.10983196626892781, 'num_leaves': 177, 'max_depth': 11, 'min_data_in_leaf': 400, 'feature_fraction': 0.8330120106397235, 'bagging_fraction': 0.9995037808436946, 'lambda_l1': 0.00186660135190575, 'lambda_l2': 4.551302862986141, 'use_scale_pos_weight': True}. Best is trial 103 with value: -0.051476061027520226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 116. Best value: -0.0514933:  98%|█████████▊| 117/120 [2:18:42<01:28, 29.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:55:40,520] Trial 116 finished with value: -0.051493306140401846 and parameters: {'learning_rate': 0.1324671713073434, 'num_leaves': 120, 'max_depth': 6, 'min_data_in_leaf': 292, 'feature_fraction': 0.8519441304304776, 'bagging_fraction': 0.9850671323806028, 'lambda_l1': 0.5111007748071288, 'lambda_l2': 0.2005510984693145, 'use_scale_pos_weight': True}. Best is trial 116 with value: -0.051493306140401846.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 116. Best value: -0.0514933:  98%|█████████▊| 118/120 [2:18:59<00:51, 25.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 16:55:57,076] Trial 117 finished with value: -0.04988943913678793 and parameters: {'learning_rate': 0.13512954335813032, 'num_leaves': 120, 'max_depth': 6, 'min_data_in_leaf': 204, 'feature_fraction': 0.7631410937412648, 'bagging_fraction': 0.9847922187501419, 'lambda_l1': 0.5964295385422944, 'lambda_l2': 0.6528321991164193, 'use_scale_pos_weight': True}. Best is trial 116 with value: -0.051493306140401846.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 116. Best value: -0.0514933:  99%|█████████▉| 119/120 [2:25:14<02:10, 130.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 17:02:12,570] Trial 118 finished with value: -0.04471465452595144 and parameters: {'learning_rate': 0.14116612976969922, 'num_leaves': 129, 'max_depth': 6, 'min_data_in_leaf': 295, 'feature_fraction': 0.8803759209024561, 'bagging_fraction': 0.9756731550402419, 'lambda_l1': 0.687372726397689, 'lambda_l2': 0.2265775822330701, 'use_scale_pos_weight': True}. Best is trial 116 with value: -0.051493306140401846.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 116. Best value: -0.0514933: 100%|██████████| 120/120 [2:30:52<00:00, 75.43s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 17:07:49,801] Trial 119 finished with value: -0.04438980645096601 and parameters: {'learning_rate': 0.1615598070637498, 'num_leaves': 109, 'max_depth': 6, 'min_data_in_leaf': 329, 'feature_fraction': 0.8522831979347928, 'bagging_fraction': 0.9902331626558243, 'lambda_l1': 0.18933989015597008, 'lambda_l2': 4.146234459824428, 'use_scale_pos_weight': True}. Best is trial 116 with value: -0.051493306140401846.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>AP</th>\n",
       "      <th>CV_LogLoss</th>\n",
       "      <th>CV_WLL</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_num_leaves</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_min_data_in_leaf</th>\n",
       "      <th>params_feature_fraction</th>\n",
       "      <th>params_bagging_fraction</th>\n",
       "      <th>params_lambda_l1</th>\n",
       "      <th>params_lambda_l2</th>\n",
       "      <th>params_use_scale_pos_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116</td>\n",
       "      <td>0.051493</td>\n",
       "      <td>0.449692</td>\n",
       "      <td>0.682932</td>\n",
       "      <td>0.132467</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>292</td>\n",
       "      <td>0.851944</td>\n",
       "      <td>0.985067</td>\n",
       "      <td>0.511101</td>\n",
       "      <td>0.200551</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>103</td>\n",
       "      <td>0.051476</td>\n",
       "      <td>0.225058</td>\n",
       "      <td>0.848284</td>\n",
       "      <td>0.096762</td>\n",
       "      <td>149</td>\n",
       "      <td>6</td>\n",
       "      <td>337</td>\n",
       "      <td>0.817208</td>\n",
       "      <td>0.891574</td>\n",
       "      <td>0.604707</td>\n",
       "      <td>0.231233</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>0.051463</td>\n",
       "      <td>0.295005</td>\n",
       "      <td>0.761026</td>\n",
       "      <td>0.110475</td>\n",
       "      <td>175</td>\n",
       "      <td>6</td>\n",
       "      <td>397</td>\n",
       "      <td>0.830057</td>\n",
       "      <td>0.992668</td>\n",
       "      <td>0.682654</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.285600</td>\n",
       "      <td>0.780256</td>\n",
       "      <td>0.108829</td>\n",
       "      <td>261</td>\n",
       "      <td>7</td>\n",
       "      <td>417</td>\n",
       "      <td>0.850602</td>\n",
       "      <td>0.808620</td>\n",
       "      <td>0.926678</td>\n",
       "      <td>0.016827</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>113</td>\n",
       "      <td>0.051360</td>\n",
       "      <td>0.286404</td>\n",
       "      <td>0.769472</td>\n",
       "      <td>0.109011</td>\n",
       "      <td>179</td>\n",
       "      <td>6</td>\n",
       "      <td>371</td>\n",
       "      <td>0.831894</td>\n",
       "      <td>0.986830</td>\n",
       "      <td>0.598349</td>\n",
       "      <td>0.385152</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>0.051355</td>\n",
       "      <td>0.327663</td>\n",
       "      <td>0.746671</td>\n",
       "      <td>0.116004</td>\n",
       "      <td>121</td>\n",
       "      <td>7</td>\n",
       "      <td>239</td>\n",
       "      <td>0.817566</td>\n",
       "      <td>0.959346</td>\n",
       "      <td>1.355391</td>\n",
       "      <td>0.235934</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>0.051240</td>\n",
       "      <td>0.400360</td>\n",
       "      <td>0.697256</td>\n",
       "      <td>0.126220</td>\n",
       "      <td>142</td>\n",
       "      <td>6</td>\n",
       "      <td>438</td>\n",
       "      <td>0.769533</td>\n",
       "      <td>0.962202</td>\n",
       "      <td>2.966409</td>\n",
       "      <td>0.020805</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>111</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>0.389832</td>\n",
       "      <td>0.702236</td>\n",
       "      <td>0.124858</td>\n",
       "      <td>158</td>\n",
       "      <td>6</td>\n",
       "      <td>370</td>\n",
       "      <td>0.834908</td>\n",
       "      <td>0.956685</td>\n",
       "      <td>0.864355</td>\n",
       "      <td>0.167959</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>101</td>\n",
       "      <td>0.051117</td>\n",
       "      <td>0.325229</td>\n",
       "      <td>0.737773</td>\n",
       "      <td>0.115529</td>\n",
       "      <td>149</td>\n",
       "      <td>6</td>\n",
       "      <td>450</td>\n",
       "      <td>0.818621</td>\n",
       "      <td>0.913775</td>\n",
       "      <td>1.281032</td>\n",
       "      <td>0.232988</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>0.051115</td>\n",
       "      <td>0.264355</td>\n",
       "      <td>0.802758</td>\n",
       "      <td>0.104995</td>\n",
       "      <td>142</td>\n",
       "      <td>7</td>\n",
       "      <td>454</td>\n",
       "      <td>0.840994</td>\n",
       "      <td>0.814785</td>\n",
       "      <td>1.077938</td>\n",
       "      <td>0.311351</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number        AP  CV_LogLoss    CV_WLL  params_learning_rate  \\\n",
       "116     116  0.051493    0.449692  0.682932              0.132467   \n",
       "103     103  0.051476    0.225058  0.848284              0.096762   \n",
       "114     114  0.051463    0.295005  0.761026              0.110475   \n",
       "61       61  0.051400    0.285600  0.780256              0.108829   \n",
       "113     113  0.051360    0.286404  0.769472              0.109011   \n",
       "97       97  0.051355    0.327663  0.746671              0.116004   \n",
       "85       85  0.051240    0.400360  0.697256              0.126220   \n",
       "111     111  0.051188    0.389832  0.702236              0.124858   \n",
       "101     101  0.051117    0.325229  0.737773              0.115529   \n",
       "62       62  0.051115    0.264355  0.802758              0.104995   \n",
       "\n",
       "     params_num_leaves  params_max_depth  params_min_data_in_leaf  \\\n",
       "116                120                 6                      292   \n",
       "103                149                 6                      337   \n",
       "114                175                 6                      397   \n",
       "61                 261                 7                      417   \n",
       "113                179                 6                      371   \n",
       "97                 121                 7                      239   \n",
       "85                 142                 6                      438   \n",
       "111                158                 6                      370   \n",
       "101                149                 6                      450   \n",
       "62                 142                 7                      454   \n",
       "\n",
       "     params_feature_fraction  params_bagging_fraction  params_lambda_l1  \\\n",
       "116                 0.851944                 0.985067          0.511101   \n",
       "103                 0.817208                 0.891574          0.604707   \n",
       "114                 0.830057                 0.992668          0.682654   \n",
       "61                  0.850602                 0.808620          0.926678   \n",
       "113                 0.831894                 0.986830          0.598349   \n",
       "97                  0.817566                 0.959346          1.355391   \n",
       "85                  0.769533                 0.962202          2.966409   \n",
       "111                 0.834908                 0.956685          0.864355   \n",
       "101                 0.818621                 0.913775          1.281032   \n",
       "62                  0.840994                 0.814785          1.077938   \n",
       "\n",
       "     params_lambda_l2  params_use_scale_pos_weight  \n",
       "116          0.200551                         True  \n",
       "103          0.231233                         True  \n",
       "114          0.148936                         True  \n",
       "61           0.016827                         True  \n",
       "113          0.385152                         True  \n",
       "97           0.235934                         True  \n",
       "85           0.020805                        False  \n",
       "111          0.167959                         True  \n",
       "101          0.232988                         True  \n",
       "62           0.311351                         True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Phase 1 — Hyperparameter tuning (Optuna, broad search)\n",
    "# - Goal: maximize AP (PR-AUC) while monitoring LogLoss\n",
    "# - Data: larger stratified subset for a stable search\n",
    "# =========================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import average_precision_score, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "TUNE_N = 1_000_000  \n",
    "\n",
    "def stratified_sample(df: pd.DataFrame, n: int, ycol: str, seed: int) -> pd.DataFrame:\n",
    "    \"\"\"Stratified sample preserving class prior.\"\"\"\n",
    "    if (n is None) or (n >= len(df)):\n",
    "        return df.sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "    pos = df[df[ycol] == 1]\n",
    "    neg = df[df[ycol] == 0]\n",
    "    rate = pos.shape[0] / max(len(df), 1)\n",
    "    n_pos = max(1, int(round(n * rate)))\n",
    "    n_neg = max(1, n - n_pos)\n",
    "    pos_s = pos.sample(min(n_pos, len(pos)), random_state=seed)\n",
    "    neg_s = neg.sample(min(n_neg, len(neg)), random_state=seed)\n",
    "    return pd.concat([pos_s, neg_s]).sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "# --- build tuning subset (train only); valid set stays fixed (X_va, y_va from above)\n",
    "tr_tune = stratified_sample(train_df, TUNE_N, TARGET_COL, SEED)\n",
    "Xt, yt = tr_tune[feat_cols].copy(), tr_tune[TARGET_COL].astype(int).to_numpy()\n",
    "\n",
    "# --- defensive: drop stray object cols and cast categories for LightGBM\n",
    "obj_cols_t = Xt.select_dtypes(include=['object']).columns.tolist()\n",
    "if obj_cols_t:\n",
    "    Xt.drop(columns=obj_cols_t, inplace=True, errors=\"ignore\")\n",
    "cat_present = [c for c in CAT_COLS_FIXED if c in Xt.columns]\n",
    "for c in cat_present:\n",
    "    if not pd.api.types.is_categorical_dtype(Xt[c]):\n",
    "        Xt[c] = Xt[c].astype('category')\n",
    "\n",
    "def objective_lgbm(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"3-fold Stratified CV with early stopping. Optimize for AP (higher is better).\"\"\"\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.02, 0.2, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 1023, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 6, 15),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 100, 5000, log=True),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
    "        \"bagging_freq\": 1,\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0.0, 10.0),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 0.0, 10.0),\n",
    "        \"verbosity\": -1,\n",
    "        \"random_state\": SEED,\n",
    "        \"n_jobs\": -1,\n",
    "    }\n",
    "\n",
    "    # imbalance handling toggle (compare is_unbalance vs scale_pos_weight)\n",
    "    use_spw = trial.suggest_categorical(\"use_scale_pos_weight\", [True, False])\n",
    "    if use_spw:\n",
    "        pos = yt.sum(); neg = len(yt) - pos\n",
    "        params[\"scale_pos_weight\"] = float(neg / max(pos, 1))\n",
    "    else:\n",
    "        params[\"is_unbalance\"] = True\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "    ap_scores, nll_scores, wll_scores = [], [], []\n",
    "\n",
    "    for tr_idx, va_idx in skf.split(Xt, yt):\n",
    "        Xtr, Xcv = Xt.iloc[tr_idx], Xt.iloc[va_idx]\n",
    "        ytr, ycv = yt[tr_idx], yt[va_idx]\n",
    "\n",
    "        clf = lgb.LGBMClassifier(\n",
    "            n_estimators=4000,\n",
    "            **params\n",
    "        )\n",
    "        clf.fit(\n",
    "            Xtr, ytr,\n",
    "            eval_set=[(Xcv, ycv)],\n",
    "            eval_metric=['binary_logloss', 'aucpr'],\n",
    "            callbacks=[lgb.early_stopping(150, verbose=False), lgb.log_evaluation(0)]\n",
    "        )\n",
    "\n",
    "        it = getattr(clf, \"best_iteration_\", None)\n",
    "        p = clf.predict_proba(Xcv, num_iteration=it)[:, 1] if it else clf.predict_proba(Xcv)[:, 1]\n",
    "\n",
    "        ap_scores.append(average_precision_score(ycv, p))\n",
    "        nll_scores.append(log_loss(ycv, p))\n",
    "        # record WLL(50:50)\n",
    "        wll_scores.append(weighted_log_loss(ycv, p, 0.5, 0.5))\n",
    "\n",
    "    trial.set_user_attr(\"cv_logloss\", float(np.mean(nll_scores)))\n",
    "    # store mean CV WLL\n",
    "    trial.set_user_attr(\"cv_wll\", float(np.mean(wll_scores)))\n",
    "    # Optuna minimizes → negative AP\n",
    "    return -float(np.mean(ap_scores))\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=\"lgbm_tune_ap\")\n",
    "study.optimize(objective_lgbm, n_trials=120, show_progress_bar=True)\n",
    "\n",
    "# --- compact Top‑K trial table for the notebook\n",
    "df_trials = study.trials_dataframe()\n",
    "topk = (df_trials.assign(AP=-df_trials[\"value\"],\n",
    "                        CV_LogLoss=df_trials[\"user_attrs_cv_logloss\"],\n",
    "                        CV_WLL=df_trials[\"user_attrs_cv_wll\"])\n",
    "                .sort_values(\"value\")\n",
    "                .head(10))\n",
    "\n",
    "display(topk[[\n",
    "    \"number\",\"AP\",\"CV_LogLoss\",\"CV_WLL\",\n",
    "    \"params_learning_rate\",\"params_num_leaves\",\"params_max_depth\",\n",
    "    \"params_min_data_in_leaf\",\"params_feature_fraction\",\"params_bagging_fraction\",\n",
    "    \"params_lambda_l1\",\"params_lambda_l2\",\"params_use_scale_pos_weight\"\n",
    "]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hg/v9v4slf113jb0w4kpzx5y_zw0000gn/T/ipykernel_77034/552147930.py:26: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(X_tr_clean[c]):\n",
      "/var/folders/hg/v9v4slf113jb0w4kpzx5y_zw0000gn/T/ipykernel_77034/552147930.py:29: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(X_va_clean[c]):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AP</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>WLL</th>\n",
       "      <th>MeanPred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best(Stage-1) + Isotonic(OOF)</td>\n",
       "      <td>0.055251</td>\n",
       "      <td>0.088486</td>\n",
       "      <td>1.835594</td>\n",
       "      <td>0.019183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM(Default Baseline)</td>\n",
       "      <td>0.049019</td>\n",
       "      <td>0.110668</td>\n",
       "      <td>1.317379</td>\n",
       "      <td>0.060929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best(Stage-1) Uncalibrated</td>\n",
       "      <td>0.055589</td>\n",
       "      <td>0.447979</td>\n",
       "      <td>0.669499</td>\n",
       "      <td>0.310960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model        AP   LogLoss       WLL  MeanPred\n",
       "0  Best(Stage-1) + Isotonic(OOF)  0.055251  0.088486  1.835594  0.019183\n",
       "1     LightGBM(Default Baseline)  0.049019  0.110668  1.317379  0.060929\n",
       "2     Best(Stage-1) Uncalibrated  0.055589  0.447979  0.669499  0.310960"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base rate (valid) = 0.019074\n",
      "[Gate] ΔAP = +0.006233, ΔLogLoss = -0.022182 (negative is better)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================================\n",
    "# Validation Gate (safe: no in-place mutation, baseline first, OOF isotonic)\n",
    "# ==========================================================================\n",
    "import json, copy, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from joblib import dump\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import average_precision_score, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# --- helpers ---\n",
    "def compute_metrics(y_true, p):\n",
    "    return {\"AP\": average_precision_score(y_true, p),\n",
    "            \"LogLoss\": log_loss(y_true, p),\n",
    "            \"WLL\": weighted_log_loss(y_true, p, 0.5, 0.5)\n",
    "            }\n",
    "\n",
    "def prepare_lgb_frames(X_tr_src, X_va_src, cat_cols):\n",
    "    X_tr_clean = X_tr_src.copy()\n",
    "    X_va_clean = X_va_src.copy()\n",
    "    obj_tr = X_tr_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "    obj_va = X_va_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "    if obj_tr: X_tr_clean.drop(columns=obj_tr, inplace=True, errors=\"ignore\")\n",
    "    if obj_va: X_va_clean.drop(columns=obj_va, inplace=True, errors=\"ignore\")\n",
    "    for c in [c for c in cat_cols if c in X_tr_clean.columns]:\n",
    "        if not pd.api.types.is_categorical_dtype(X_tr_clean[c]):\n",
    "            X_tr_clean[c] = X_tr_clean[c].astype(\"category\")\n",
    "    for c in [c for c in cat_cols if c in X_va_clean.columns]:\n",
    "        if not pd.api.types.is_categorical_dtype(X_va_clean[c]):\n",
    "            X_va_clean[c] = X_va_clean[c].astype(\"category\")\n",
    "    return X_tr_clean, X_va_clean\n",
    "\n",
    "ART_DIR = Path(\"./artifacts/optuna_lgbm\"); ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "def _save_df(df, name): df.to_csv(ART_DIR / f\"{name}.csv\", index=False)\n",
    "def _save_json(obj, name): (ART_DIR / f\"{name}.json\").write_text(json.dumps(obj, indent=2))\n",
    "\n",
    "# --- clean frames (no in-place) ---\n",
    "X_tr_clean, X_va_clean = prepare_lgb_frames(X_tr, X_va, CAT_COLS_FIXED)\n",
    "\n",
    "# --- baseline first (independent) ---\n",
    "lgb_base = lgb.LGBMClassifier(\n",
    "    n_estimators=2000, learning_rate=0.05, objective=\"binary\",\n",
    "    is_unbalance=True, random_state=SEED, n_jobs=-1\n",
    ")\n",
    "lgb_base.fit(\n",
    "    X_tr_clean, y_tr,\n",
    "    eval_set=[(X_va_clean, y_va)],\n",
    "    eval_metric=\"binary_logloss\",\n",
    "    callbacks=[lgb.early_stopping(100, verbose=False)]\n",
    ")\n",
    "p_base = lgb_base.predict_proba(X_va_clean)[:, 1]\n",
    "m_base = compute_metrics(y_va, p_base)\n",
    "\n",
    "# --- best params (no mutation of originals) ---\n",
    "best = copy.deepcopy(study.best_trial.params)\n",
    "use_spw = best.pop(\"use_scale_pos_weight\", True)\n",
    "if use_spw:\n",
    "    pos = int(y_tr.sum()); neg = len(y_tr) - pos\n",
    "    best[\"scale_pos_weight\"] = float(neg / max(pos, 1))\n",
    "else:\n",
    "    best[\"is_unbalance\"] = True\n",
    "best.setdefault(\"bagging_freq\", 1)\n",
    "best.update(dict(objective=\"binary\", metric=\"binary_logloss\", random_state=SEED, n_jobs=-1))\n",
    "_save_json(best, \"best_params_valid_gate\")\n",
    "\n",
    "# --- OOF isotonic calibration ---\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "oof_pred = np.zeros_like(y_tr, dtype=float)\n",
    "for tr_idx, va_idx in skf.split(X_tr_clean, y_tr):\n",
    "    clf_cv = lgb.LGBMClassifier(n_estimators=4000, **best)\n",
    "    clf_cv.fit(\n",
    "        X_tr_clean.iloc[tr_idx], y_tr[tr_idx],\n",
    "        eval_set=[(X_tr_clean.iloc[va_idx], y_tr[va_idx])],\n",
    "        eval_metric=[\"binary_logloss\",\"aucpr\"],\n",
    "        callbacks=[lgb.early_stopping(150, verbose=False)]\n",
    "    )\n",
    "    oof_pred[va_idx] = clf_cv.predict_proba(X_tr_clean.iloc[va_idx])[:, 1]\n",
    "\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "iso = IsotonicRegression(y_min=0.0, y_max=1.0, out_of_bounds=\"clip\")\n",
    "iso.fit(oof_pred, y_tr)\n",
    "dump(iso, ART_DIR / \"isotonic_stage1.joblib\")\n",
    "\n",
    "# --- full-train fit (uncalibrated) + calibrated eval on the SAME valid set ---\n",
    "lgb_best = lgb.LGBMClassifier(n_estimators=6000, **best)\n",
    "lgb_best.fit(\n",
    "    X_tr_clean, y_tr,\n",
    "    eval_set=[(X_va_clean, y_va)],\n",
    "    eval_metric=[\"binary_logloss\",\"aucpr\"],\n",
    "    callbacks=[lgb.early_stopping(200, verbose=False)]\n",
    ")\n",
    "p_uncal = lgb_best.predict_proba(X_va_clean)[:, 1]\n",
    "p_cal   = iso.transform(p_uncal)\n",
    "\n",
    "m_uncal = compute_metrics(y_va, p_uncal)\n",
    "m_cal   = compute_metrics(y_va, p_cal)\n",
    "\n",
    "# --- report (no NaNs) ---\n",
    "cmp = pd.DataFrame([\n",
    "    {\"Model\": \"LightGBM(Default Baseline)\",    **m_base,  \"MeanPred\": float(p_base.mean())},\n",
    "    {\"Model\": \"Best(Stage-1) Uncalibrated\",    **m_uncal, \"MeanPred\": float(p_uncal.mean())},\n",
    "    {\"Model\": \"Best(Stage-1) + Isotonic(OOF)\", **m_cal,   \"MeanPred\": float(p_cal.mean())},\n",
    "]).sort_values([\"LogLoss\",\"AP\"], ascending=[True, False]).reset_index(drop=True)\n",
    "display(cmp)\n",
    "\n",
    "# --- gating on calibrated metrics ---\n",
    "delta_ap = m_cal[\"AP\"] - m_base[\"AP\"]\n",
    "delta_ll = m_cal[\"LogLoss\"] - m_base[\"LogLoss\"]  # negative is better\n",
    "print(f\"Base rate (valid) = {y_va.mean():.6f}\")\n",
    "print(f\"[Gate] ΔAP = {delta_ap:+.6f}, ΔLogLoss = {delta_ll:+.6f} (negative is better)\")\n",
    "\n",
    "# --- artifacts ---\n",
    "_save_df(cmp, \"valid_gate_comparison_calibrated_safe\")\n",
    "np.save(ART_DIR / \"p_valid_baseline.npy\", p_base)\n",
    "np.save(ART_DIR / \"p_valid_uncal.npy\", p_uncal)\n",
    "np.save(ART_DIR / \"p_valid_calibrated.npy\", p_cal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Gate (report-only, no selection)\n",
    "\n",
    "- After Stage‑1 tuning on **train CV only**, we fit **isotonic calibration** using **train OOF** and evaluated **once** on `valid`.\n",
    "- Results vs. default LightGBM:\n",
    "  - **AP**: +0.0062 (better ranking under imbalance)\n",
    "  - **LogLoss**: −0.0222 (reduced over‑confidence; better probability quality)\n",
    "  - **WLL (50:50)**: increased (expected when calibration lowers probabilities toward the base rate; positive-class term −log(p) grows)\n",
    "- Mean predicted probability moved from **0.311 (uncal.) → 0.019 (cal.)**, matching the base rate (~0.019). This confirms **successful probability calibration**.\n",
    "\n",
    "We will proceed to Stage‑2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hg/v9v4slf113jb0w4kpzx5y_zw0000gn/T/ipykernel_77034/2581621568.py:32: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if c in X_tr_clean.columns and not pd.api.types.is_categorical_dtype(X_tr_clean[c]):\n",
      "/var/folders/hg/v9v4slf113jb0w4kpzx5y_zw0000gn/T/ipykernel_77034/2581621568.py:34: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if c in X_va_clean.columns and not pd.api.types.is_categorical_dtype(X_va_clean[c]):\n",
      "/var/folders/hg/v9v4slf113jb0w4kpzx5y_zw0000gn/T/ipykernel_77034/2581621568.py:32: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if c in X_tr_clean.columns and not pd.api.types.is_categorical_dtype(X_tr_clean[c]):\n",
      "/var/folders/hg/v9v4slf113jb0w4kpzx5y_zw0000gn/T/ipykernel_77034/2581621568.py:34: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if c in X_va_clean.columns and not pd.api.types.is_categorical_dtype(X_va_clean[c]):\n",
      "[I 2025-09-15 13:17:11,926] A new study created in memory with name: lgbm_stage2_ap\n",
      "Best trial: 0. Best value: -0.0510936:   2%|▏         | 1/50 [00:24<19:58, 24.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:17:36,393] Trial 0 finished with value: -0.051093644089789246 and parameters: {'learning_rate': 0.10519257551377724, 'max_depth': 6, 'num_leaves': 93, 'min_data_in_leaf': 226, 'feature_fraction': 0.7345623372477302, 'bagging_fraction': 0.897435891635037, 'lambda_l1': 0.48409465644934, 'lambda_l2': 0.19454957103077658, 'min_split_gain': 0.028382364435816272}. Best is trial 0 with value: -0.051093644089789246.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: -0.0511808:   4%|▍         | 2/50 [00:48<19:23, 24.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:18:00,484] Trial 1 finished with value: -0.051180790771154755 and parameters: {'learning_rate': 0.11823574909163727, 'max_depth': 6, 'num_leaves': 110, 'min_data_in_leaf': 216, 'feature_fraction': 0.8948901666653922, 'bagging_fraction': 0.9058737794000193, 'lambda_l1': 1.327548989900747, 'lambda_l2': 0.201703285888474, 'min_split_gain': 0.016403230252382484}. Best is trial 1 with value: -0.051180790771154755.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: -0.0511808:   6%|▌         | 3/50 [01:07<17:13, 22.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:18:19,811] Trial 2 finished with value: -0.0487918507437178 and parameters: {'learning_rate': 0.12202484623981676, 'max_depth': 5, 'num_leaves': 101, 'min_data_in_leaf': 285, 'feature_fraction': 0.8937205643556794, 'bagging_fraction': 0.999347393292696, 'lambda_l1': 0.6172382782906854, 'lambda_l2': 0.23589130147574452, 'min_split_gain': 0.01092873940319305}. Best is trial 1 with value: -0.051180790771154755.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: -0.0511808:   8%|▊         | 4/50 [01:32<17:32, 22.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:18:44,023] Trial 3 finished with value: -0.05111155229193648 and parameters: {'learning_rate': 0.13140258352766382, 'max_depth': 6, 'num_leaves': 153, 'min_data_in_leaf': 391, 'feature_fraction': 0.8426504188541792, 'bagging_fraction': 0.8883298862155926, 'lambda_l1': 0.577749599234708, 'lambda_l2': 0.24524057776329103, 'min_split_gain': 0.010163991176828075}. Best is trial 1 with value: -0.051180790771154755.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.0523584:  10%|█         | 5/50 [01:55<17:22, 23.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:19:07,719] Trial 4 finished with value: -0.052358417706816235 and parameters: {'learning_rate': 0.11109306868739095, 'max_depth': 6, 'num_leaves': 83, 'min_data_in_leaf': 189, 'feature_fraction': 0.7654262431128641, 'bagging_fraction': 0.9603892055361379, 'lambda_l1': 0.6504695949515136, 'lambda_l2': 0.16153575817849944, 'min_split_gain': 0.03713858649772635}. Best is trial 4 with value: -0.052358417706816235.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.0523584:  12%|█▏        | 6/50 [02:23<18:11, 24.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:19:35,690] Trial 5 finished with value: -0.04954710913874379 and parameters: {'learning_rate': 0.09752138901569164, 'max_depth': 7, 'num_leaves': 90, 'min_data_in_leaf': 317, 'feature_fraction': 0.8639859504047933, 'bagging_fraction': 0.9009068084296864, 'lambda_l1': 1.0235013861717164, 'lambda_l2': 0.22606272861690058, 'min_split_gain': 0.015075278485210604}. Best is trial 4 with value: -0.052358417706816235.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.0523584:  14%|█▍        | 7/50 [02:42<16:23, 22.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:19:54,595] Trial 6 finished with value: -0.0476501510382925 and parameters: {'learning_rate': 0.13162686207223187, 'max_depth': 5, 'num_leaves': 90, 'min_data_in_leaf': 344, 'feature_fraction': 0.894395772257856, 'bagging_fraction': 0.8678300312305752, 'lambda_l1': 1.064787172553701, 'lambda_l2': 0.19477390493334004, 'min_split_gain': 0.003196476875312504}. Best is trial 4 with value: -0.052358417706816235.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.0523584:  16%|█▌        | 8/50 [03:09<16:51, 24.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:20:21,297] Trial 7 finished with value: -0.049074776324552316 and parameters: {'learning_rate': 0.102148331406518, 'max_depth': 7, 'num_leaves': 82, 'min_data_in_leaf': 277, 'feature_fraction': 0.8494823337089601, 'bagging_fraction': 0.8735584757532063, 'lambda_l1': 0.8901356162828991, 'lambda_l2': 0.19497033567008504, 'min_split_gain': 0.019213936081805064}. Best is trial 4 with value: -0.052358417706816235.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.0523584:  18%|█▊        | 9/50 [03:33<16:34, 24.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:20:45,909] Trial 8 finished with value: -0.05139051206907225 and parameters: {'learning_rate': 0.13879395273182327, 'max_depth': 6, 'num_leaves': 137, 'min_data_in_leaf': 212, 'feature_fraction': 0.835767089005656, 'bagging_fraction': 0.9178393382064586, 'lambda_l1': 0.5871898426095306, 'lambda_l2': 0.14806337978120357, 'min_split_gain': 0.00784086186840456}. Best is trial 4 with value: -0.052358417706816235.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: -0.0525586:  20%|██        | 10/50 [04:02<17:02, 25.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:21:14,417] Trial 9 finished with value: -0.052558608291613185 and parameters: {'learning_rate': 0.11418475709161492, 'max_depth': 7, 'num_leaves': 168, 'min_data_in_leaf': 176, 'feature_fraction': 0.7121838401945978, 'bagging_fraction': 0.899357421420207, 'lambda_l1': 0.6600233302749973, 'lambda_l2': 0.168434257495389, 'min_split_gain': 0.01817176728968672}. Best is trial 9 with value: -0.052558608291613185.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: -0.0525586:  22%|██▏       | 11/50 [04:31<17:14, 26.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:21:43,139] Trial 10 finished with value: -0.05245777426033549 and parameters: {'learning_rate': 0.11191797892100142, 'max_depth': 7, 'num_leaves': 166, 'min_data_in_leaf': 184, 'feature_fraction': 0.7740482435793182, 'bagging_fraction': 0.9434118476653097, 'lambda_l1': 0.7884021709893403, 'lambda_l2': 0.16602923881063283, 'min_split_gain': 0.04557658917280824}. Best is trial 9 with value: -0.052558608291613185.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: -0.0526406:  24%|██▍       | 12/50 [05:00<17:20, 27.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:22:12,427] Trial 11 finished with value: -0.05264062820946322 and parameters: {'learning_rate': 0.11273449368482745, 'max_depth': 7, 'num_leaves': 157, 'min_data_in_leaf': 175, 'feature_fraction': 0.7070824615476028, 'bagging_fraction': 0.9436289480566555, 'lambda_l1': 0.802152115310649, 'lambda_l2': 0.16541278239617022, 'min_split_gain': 0.04767757121066686}. Best is trial 11 with value: -0.05264062820946322.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: -0.0526406:  26%|██▌       | 13/50 [05:29<17:12, 27.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:22:41,519] Trial 12 finished with value: -0.05255764334312277 and parameters: {'learning_rate': 0.1214935466105688, 'max_depth': 7, 'num_leaves': 130, 'min_data_in_leaf': 177, 'feature_fraction': 0.7080935085141206, 'bagging_fraction': 0.941946916064107, 'lambda_l1': 0.8193746676633802, 'lambda_l2': 0.13415877822495698, 'min_split_gain': 0.028102263793744833}. Best is trial 11 with value: -0.05264062820946322.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.0537629:  28%|██▊       | 14/50 [05:57<16:46, 27.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:23:09,616] Trial 13 finished with value: -0.053762899299794976 and parameters: {'learning_rate': 0.11009184092610899, 'max_depth': 7, 'num_leaves': 127, 'min_data_in_leaf': 241, 'feature_fraction': 0.9541671203915126, 'bagging_fraction': 0.9705346701461524, 'lambda_l1': 0.7636958167021123, 'lambda_l2': 0.17547471226591355, 'min_split_gain': 0.04917372836922867}. Best is trial 13 with value: -0.053762899299794976.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: -0.0539878:  30%|███       | 15/50 [06:25<16:14, 27.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:23:37,202] Trial 14 finished with value: -0.053987824597833585 and parameters: {'learning_rate': 0.10613329561566544, 'max_depth': 7, 'num_leaves': 121, 'min_data_in_leaf': 245, 'feature_fraction': 0.949677245339242, 'bagging_fraction': 0.9783274952241873, 'lambda_l1': 1.0505927572648195, 'lambda_l2': 0.1773657363956775, 'min_split_gain': 0.04937393266576854}. Best is trial 14 with value: -0.053987824597833585.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: -0.0539878:  32%|███▏      | 16/50 [06:53<15:52, 28.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:24:05,658] Trial 15 finished with value: -0.05358578934257352 and parameters: {'learning_rate': 0.10502349507790935, 'max_depth': 7, 'num_leaves': 120, 'min_data_in_leaf': 246, 'feature_fraction': 0.9362015765182508, 'bagging_fraction': 0.98532521033551, 'lambda_l1': 1.1759977102169659, 'lambda_l2': 0.21406020686675212, 'min_split_gain': 0.039135990527274976}. Best is trial 14 with value: -0.053987824597833585.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: -0.0539878:  34%|███▍      | 17/50 [07:22<15:36, 28.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:24:34,901] Trial 16 finished with value: -0.05397480219197683 and parameters: {'learning_rate': 0.09571103924301651, 'max_depth': 7, 'num_leaves': 113, 'min_data_in_leaf': 246, 'feature_fraction': 0.9545758313450661, 'bagging_fraction': 0.965499527575937, 'lambda_l1': 1.0134662376693924, 'lambda_l2': 0.17920840496097565, 'min_split_gain': 0.03941696028126447}. Best is trial 14 with value: -0.053987824597833585.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: -0.0539878:  36%|███▌      | 18/50 [07:51<15:07, 28.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:25:03,184] Trial 17 finished with value: -0.052818857845249645 and parameters: {'learning_rate': 0.09365867189726026, 'max_depth': 7, 'num_leaves': 110, 'min_data_in_leaf': 258, 'feature_fraction': 0.924284955355648, 'bagging_fraction': 0.9678360867265504, 'lambda_l1': 1.1922826271988602, 'lambda_l2': 0.183496814995078, 'min_split_gain': 0.03863671218650999}. Best is trial 14 with value: -0.053987824597833585.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: -0.0539878:  38%|███▊      | 19/50 [08:09<13:04, 25.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:25:21,402] Trial 18 finished with value: -0.04915475172681119 and parameters: {'learning_rate': 0.09306265084078186, 'max_depth': 5, 'num_leaves': 73, 'min_data_in_leaf': 326, 'feature_fraction': 0.9555717140349892, 'bagging_fraction': 0.9887380997185048, 'lambda_l1': 1.0019992941352531, 'lambda_l2': 0.15216305547793585, 'min_split_gain': 0.032992528230429245}. Best is trial 14 with value: -0.053987824597833585.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: -0.0539878:  40%|████      | 20/50 [08:31<12:09, 24.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:25:43,381] Trial 19 finished with value: -0.05206043287657073 and parameters: {'learning_rate': 0.09950329211327795, 'max_depth': 6, 'num_leaves': 118, 'min_data_in_leaf': 205, 'feature_fraction': 0.8068000422908936, 'bagging_fraction': 0.9587065757232435, 'lambda_l1': 1.1472690375310424, 'lambda_l2': 0.1841458453759052, 'min_split_gain': 0.043274490209411265}. Best is trial 14 with value: -0.053987824597833585.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: -0.0539878:  42%|████▏     | 21/50 [08:53<11:25, 23.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:26:05,494] Trial 20 finished with value: -0.051664756305611126 and parameters: {'learning_rate': 0.10649129614645511, 'max_depth': 6, 'num_leaves': 139, 'min_data_in_leaf': 297, 'feature_fraction': 0.9182495414599011, 'bagging_fraction': 0.9802140141561353, 'lambda_l1': 1.3424258042376866, 'lambda_l2': 0.20674262755157619, 'min_split_gain': 0.04272069562784477}. Best is trial 14 with value: -0.053987824597833585.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: -0.053994:  44%|████▍     | 22/50 [09:20<11:32, 24.75s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:26:32,793] Trial 21 finished with value: -0.0539939983220027 and parameters: {'learning_rate': 0.10832312355596115, 'max_depth': 7, 'num_leaves': 124, 'min_data_in_leaf': 241, 'feature_fraction': 0.9538993867372914, 'bagging_fraction': 0.9748460693665901, 'lambda_l1': 0.9497305298484194, 'lambda_l2': 0.17817037768931787, 'min_split_gain': 0.04928177827385461}. Best is trial 21 with value: -0.0539939983220027.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: -0.053994:  46%|████▌     | 23/50 [09:47<11:24, 25.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:26:59,514] Trial 22 finished with value: -0.051467777759399314 and parameters: {'learning_rate': 0.09858937240731648, 'max_depth': 7, 'num_leaves': 100, 'min_data_in_leaf': 232, 'feature_fraction': 0.9131550940366281, 'bagging_fraction': 0.9988757679184742, 'lambda_l1': 0.9261243231188432, 'lambda_l2': 0.17955706218166134, 'min_split_gain': 0.04893601530580992}. Best is trial 21 with value: -0.0539939983220027.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: -0.053994:  48%|████▊     | 24/50 [10:14<11:14, 25.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:27:26,823] Trial 23 finished with value: -0.0533837688213523 and parameters: {'learning_rate': 0.10783186914944899, 'max_depth': 7, 'num_leaves': 117, 'min_data_in_leaf': 260, 'feature_fraction': 0.939314853327363, 'bagging_fraction': 0.9547059085804227, 'lambda_l1': 0.9362135746403984, 'lambda_l2': 0.15406183993376973, 'min_split_gain': 0.042878974377010444}. Best is trial 21 with value: -0.0539939983220027.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: -0.053994:  50%|█████     | 25/50 [10:42<10:57, 26.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:27:53,995] Trial 24 finished with value: -0.05218228125028935 and parameters: {'learning_rate': 0.1023019405875491, 'max_depth': 7, 'num_leaves': 103, 'min_data_in_leaf': 254, 'feature_fraction': 0.879000348399429, 'bagging_fraction': 0.9743191176263503, 'lambda_l1': 1.09532602578598, 'lambda_l2': 0.174177461875403, 'min_split_gain': 0.035264912329293914}. Best is trial 21 with value: -0.0539939983220027.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: -0.053994:  52%|█████▏    | 26/50 [11:10<10:47, 26.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:28:22,531] Trial 25 finished with value: -0.05241807164972762 and parameters: {'learning_rate': 0.11784224829996093, 'max_depth': 7, 'num_leaves': 128, 'min_data_in_leaf': 197, 'feature_fraction': 0.940478643099789, 'bagging_fraction': 0.9224906069965311, 'lambda_l1': 1.2455028131749029, 'lambda_l2': 0.18649271245885302, 'min_split_gain': 0.04986072096994252}. Best is trial 21 with value: -0.0539939983220027.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: -0.053994:  54%|█████▍    | 27/50 [11:39<10:30, 27.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:28:50,936] Trial 26 finished with value: -0.053090746517220094 and parameters: {'learning_rate': 0.09594561461932172, 'max_depth': 7, 'num_leaves': 142, 'min_data_in_leaf': 224, 'feature_fraction': 0.9128457968572427, 'bagging_fraction': 0.9344699794282421, 'lambda_l1': 0.992619070150142, 'lambda_l2': 0.14150004626435317, 'min_split_gain': 0.04099167179260161}. Best is trial 21 with value: -0.0539939983220027.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: -0.053994:  56%|█████▌    | 28/50 [12:00<09:27, 25.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:29:12,912] Trial 27 finished with value: -0.052315119687877255 and parameters: {'learning_rate': 0.10284602141641677, 'max_depth': 6, 'num_leaves': 114, 'min_data_in_leaf': 270, 'feature_fraction': 0.8143144709983731, 'bagging_fraction': 0.9894546118708396, 'lambda_l1': 0.8845157836213022, 'lambda_l2': 0.2084707483024014, 'min_split_gain': 0.03263250841067038}. Best is trial 21 with value: -0.0539939983220027.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: -0.053994:  58%|█████▊    | 29/50 [12:28<09:13, 26.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:29:40,565] Trial 28 finished with value: -0.05385529425039398 and parameters: {'learning_rate': 0.10814955536385504, 'max_depth': 7, 'num_leaves': 124, 'min_data_in_leaf': 239, 'feature_fraction': 0.9517634381301953, 'bagging_fraction': 0.9614253855370093, 'lambda_l1': 1.0780318815604448, 'lambda_l2': 0.15708495460231092, 'min_split_gain': 0.04551474365893349}. Best is trial 21 with value: -0.0539939983220027.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: -0.053994:  60%|██████    | 30/50 [12:50<08:20, 25.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:30:02,497] Trial 29 finished with value: -0.052659833021406456 and parameters: {'learning_rate': 0.10053881770941771, 'max_depth': 6, 'num_leaves': 103, 'min_data_in_leaf': 227, 'feature_fraction': 0.9284184347590558, 'bagging_fraction': 0.9777681278959865, 'lambda_l1': 1.2722737247216187, 'lambda_l2': 0.17296781619000395, 'min_split_gain': 0.02254042045553392}. Best is trial 21 with value: -0.0539939983220027.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: -0.053994:  62%|██████▏   | 31/50 [13:18<08:13, 25.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:30:30,675] Trial 30 finished with value: -0.05281676740650939 and parameters: {'learning_rate': 0.1046858566828255, 'max_depth': 7, 'num_leaves': 143, 'min_data_in_leaf': 305, 'feature_fraction': 0.8802089831587119, 'bagging_fraction': 0.9523713343376435, 'lambda_l1': 0.9682188377031273, 'lambda_l2': 0.19071704962911434, 'min_split_gain': 0.04578994346628296}. Best is trial 21 with value: -0.0539939983220027.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: -0.053994:  64%|██████▍   | 32/50 [13:47<08:01, 26.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:30:59,203] Trial 31 finished with value: -0.053902979491365 and parameters: {'learning_rate': 0.10830361965945154, 'max_depth': 7, 'num_leaves': 123, 'min_data_in_leaf': 239, 'feature_fraction': 0.954854342028103, 'bagging_fraction': 0.9671013163957178, 'lambda_l1': 1.0956746898601348, 'lambda_l2': 0.1603666309599485, 'min_split_gain': 0.0454636562668774}. Best is trial 21 with value: -0.0539939983220027.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: -0.053994:  66%|██████▌   | 33/50 [14:15<07:43, 27.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:31:27,739] Trial 32 finished with value: -0.05363652721153877 and parameters: {'learning_rate': 0.11506598297392912, 'max_depth': 7, 'num_leaves': 133, 'min_data_in_leaf': 211, 'feature_fraction': 0.9102123921308091, 'bagging_fraction': 0.9678024391549621, 'lambda_l1': 1.1152915297735853, 'lambda_l2': 0.17956545379817934, 'min_split_gain': 0.04548318151062318}. Best is trial 21 with value: -0.0539939983220027.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: -0.053994:  68%|██████▊   | 34/50 [14:44<07:23, 27.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:31:56,455] Trial 33 finished with value: -0.05234540580373095 and parameters: {'learning_rate': 0.1088662567511069, 'max_depth': 7, 'num_leaves': 109, 'min_data_in_leaf': 220, 'feature_fraction': 0.940399864311461, 'bagging_fraction': 0.9830214466160959, 'lambda_l1': 1.0605590699227425, 'lambda_l2': 0.1994000026184215, 'min_split_gain': 0.04135688420263509}. Best is trial 21 with value: -0.0539939983220027.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: -0.0543491:  70%|███████   | 35/50 [15:12<06:56, 27.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:32:24,292] Trial 34 finished with value: -0.05434912549792687 and parameters: {'learning_rate': 0.12015576035603917, 'max_depth': 7, 'num_leaves': 122, 'min_data_in_leaf': 285, 'feature_fraction': 0.9543999885041992, 'bagging_fraction': 0.9915910251552823, 'lambda_l1': 0.8702590737492601, 'lambda_l2': 0.1621263416382553, 'min_split_gain': 0.030154761119071012}. Best is trial 34 with value: -0.05434912549792687.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: -0.0543491:  72%|███████▏  | 36/50 [15:34<06:06, 26.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:32:46,897] Trial 35 finished with value: -0.05232335819299249 and parameters: {'learning_rate': 0.11943502848395432, 'max_depth': 6, 'num_leaves': 111, 'min_data_in_leaf': 285, 'feature_fraction': 0.8954050930009548, 'bagging_fraction': 0.9967209069488758, 'lambda_l1': 0.8548330071653929, 'lambda_l2': 0.16885739026762675, 'min_split_gain': 0.026994110946896053}. Best is trial 34 with value: -0.05434912549792687.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: -0.0543491:  74%|███████▍  | 37/50 [16:03<05:48, 26.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:33:15,016] Trial 36 finished with value: -0.05121026289164799 and parameters: {'learning_rate': 0.12657806231010496, 'max_depth': 7, 'num_leaves': 97, 'min_data_in_leaf': 274, 'feature_fraction': 0.9284123533531565, 'bagging_fraction': 0.9918001125738372, 'lambda_l1': 0.6859588417885119, 'lambda_l2': 0.14558731762751442, 'min_split_gain': 0.03212992146803683}. Best is trial 34 with value: -0.05434912549792687.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: -0.0543491:  76%|███████▌  | 38/50 [16:26<05:10, 25.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:33:38,839] Trial 37 finished with value: -0.05292316981515185 and parameters: {'learning_rate': 0.12485173138124428, 'max_depth': 6, 'num_leaves': 150, 'min_data_in_leaf': 365, 'feature_fraction': 0.8987260332939153, 'bagging_fraction': 0.976984255182008, 'lambda_l1': 0.7301692644856534, 'lambda_l2': 0.1893923754607214, 'min_split_gain': 0.023509073403232123}. Best is trial 34 with value: -0.05434912549792687.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: -0.0543491:  78%|███████▊  | 39/50 [16:45<04:21, 23.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:33:57,818] Trial 38 finished with value: -0.048710801018898624 and parameters: {'learning_rate': 0.1171961904736187, 'max_depth': 5, 'num_leaves': 107, 'min_data_in_leaf': 284, 'feature_fraction': 0.8660021271236459, 'bagging_fraction': 0.9507764222362041, 'lambda_l1': 0.48971405784747857, 'lambda_l2': 0.21923159790919056, 'min_split_gain': 0.03559319320525315}. Best is trial 34 with value: -0.05434912549792687.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: -0.0543491:  80%|████████  | 40/50 [17:14<04:11, 25.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:34:26,017] Trial 39 finished with value: -0.05221619834049388 and parameters: {'learning_rate': 0.12662146005577407, 'max_depth': 7, 'num_leaves': 115, 'min_data_in_leaf': 254, 'feature_fraction': 0.9407171719233517, 'bagging_fraction': 0.8875910876037092, 'lambda_l1': 1.0318937810753994, 'lambda_l2': 0.16121192331786732, 'min_split_gain': 0.030763961854695626}. Best is trial 34 with value: -0.05434912549792687.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: -0.0543491:  82%|████████▏ | 41/50 [17:41<03:52, 25.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:34:53,502] Trial 40 finished with value: -0.0538781170122948 and parameters: {'learning_rate': 0.09544177166033634, 'max_depth': 7, 'num_leaves': 135, 'min_data_in_leaf': 301, 'feature_fraction': 0.7646238084305104, 'bagging_fraction': 0.9946614623436983, 'lambda_l1': 0.9402501536077097, 'lambda_l2': 0.17906326923874133, 'min_split_gain': 0.03738700728205165}. Best is trial 34 with value: -0.05434912549792687.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: -0.0543491:  84%|████████▍ | 42/50 [18:10<03:33, 26.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:35:21,997] Trial 41 finished with value: -0.05370972877424721 and parameters: {'learning_rate': 0.12029039557653166, 'max_depth': 7, 'num_leaves': 123, 'min_data_in_leaf': 234, 'feature_fraction': 0.9555913982887821, 'bagging_fraction': 0.9641345996258914, 'lambda_l1': 0.8745162712407993, 'lambda_l2': 0.15953945681987555, 'min_split_gain': 0.04604075681010824}. Best is trial 34 with value: -0.05434912549792687.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: -0.0543491:  86%|████████▌ | 43/50 [18:37<03:08, 26.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:35:49,549] Trial 42 finished with value: -0.054139161967927125 and parameters: {'learning_rate': 0.11307357014171855, 'max_depth': 7, 'num_leaves': 121, 'min_data_in_leaf': 248, 'feature_fraction': 0.9453569153002704, 'bagging_fraction': 0.9735400934482935, 'lambda_l1': 1.017980215520276, 'lambda_l2': 0.16904815543719365, 'min_split_gain': 0.04063677106778334}. Best is trial 34 with value: -0.05434912549792687.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: -0.0543491:  88%|████████▊ | 44/50 [19:05<02:43, 27.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:36:17,770] Trial 43 finished with value: -0.053195181402958 and parameters: {'learning_rate': 0.1128883472513266, 'max_depth': 7, 'num_leaves': 120, 'min_data_in_leaf': 249, 'feature_fraction': 0.9289664108683782, 'bagging_fraction': 0.9833965688098263, 'lambda_l1': 0.9680772438290117, 'lambda_l2': 0.1703999775108983, 'min_split_gain': 0.04097855936625182}. Best is trial 34 with value: -0.05434912549792687.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: -0.0543491:  90%|█████████ | 45/50 [19:33<02:17, 27.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:36:45,592] Trial 44 finished with value: -0.053701552700052224 and parameters: {'learning_rate': 0.12386112585209776, 'max_depth': 7, 'num_leaves': 113, 'min_data_in_leaf': 264, 'feature_fraction': 0.9062072160359534, 'bagging_fraction': 0.9728189186009287, 'lambda_l1': 1.032368510588635, 'lambda_l2': 0.19819242609710963, 'min_split_gain': 0.03496968984290172}. Best is trial 34 with value: -0.05434912549792687.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 45. Best value: -0.0543694:  92%|█████████▏| 46/50 [20:01<01:50, 27.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:37:13,226] Trial 45 finished with value: -0.05436942153073518 and parameters: {'learning_rate': 0.11048876650703676, 'max_depth': 7, 'num_leaves': 129, 'min_data_in_leaf': 273, 'feature_fraction': 0.9456738992457049, 'bagging_fraction': 0.987419727131579, 'lambda_l1': 0.8318228310762739, 'lambda_l2': 0.1639954488452258, 'min_split_gain': 0.029726464598479937}. Best is trial 45 with value: -0.05436942153073518.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 46. Best value: -0.0543901:  94%|█████████▍| 47/50 [20:28<01:21, 27.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:37:39,955] Trial 46 finished with value: -0.054390127731745286 and parameters: {'learning_rate': 0.11546114493655109, 'max_depth': 7, 'num_leaves': 131, 'min_data_in_leaf': 286, 'feature_fraction': 0.9430871777288145, 'bagging_fraction': 0.987869277912243, 'lambda_l1': 0.83406752481746, 'lambda_l2': 0.14916132555033607, 'min_split_gain': 0.024707296841925137}. Best is trial 46 with value: -0.054390127731745286.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 46. Best value: -0.0543901:  96%|█████████▌| 48/50 [20:54<00:54, 27.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:38:06,488] Trial 47 finished with value: -0.05398886484992709 and parameters: {'learning_rate': 0.11545284400088421, 'max_depth': 7, 'num_leaves': 147, 'min_data_in_leaf': 318, 'feature_fraction': 0.9207097470606758, 'bagging_fraction': 0.990160682875674, 'lambda_l1': 0.8268333497751432, 'lambda_l2': 0.13824562334988194, 'min_split_gain': 0.020496028788495997}. Best is trial 46 with value: -0.054390127731745286.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 46. Best value: -0.0543901:  98%|█████████▊| 49/50 [21:20<00:26, 26.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:38:32,679] Trial 48 finished with value: -0.05365353337825992 and parameters: {'learning_rate': 0.11070769447988787, 'max_depth': 7, 'num_leaves': 131, 'min_data_in_leaf': 291, 'feature_fraction': 0.9352985518525133, 'bagging_fraction': 0.9992890910043127, 'lambda_l1': 0.7499601555791542, 'lambda_l2': 0.14917225963331196, 'min_split_gain': 0.02618775994611701}. Best is trial 46 with value: -0.054390127731745286.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 46. Best value: -0.0543901: 100%|██████████| 50/50 [21:47<00:00, 26.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 13:38:59,392] Trial 49 finished with value: -0.05372257205773834 and parameters: {'learning_rate': 0.11669542168742904, 'max_depth': 7, 'num_leaves': 156, 'min_data_in_leaf': 280, 'feature_fraction': 0.9443184578923082, 'bagging_fraction': 0.9845583177548589, 'lambda_l1': 0.7137198580048357, 'lambda_l2': 0.16376881464837112, 'min_split_gain': 0.029452635982864427}. Best is trial 46 with value: -0.054390127731745286.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>AP</th>\n",
       "      <th>CV_LogLoss</th>\n",
       "      <th>CV_WLL</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_num_leaves</th>\n",
       "      <th>params_min_data_in_leaf</th>\n",
       "      <th>params_feature_fraction</th>\n",
       "      <th>params_bagging_fraction</th>\n",
       "      <th>params_lambda_l1</th>\n",
       "      <th>params_lambda_l2</th>\n",
       "      <th>params_min_split_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0.054390</td>\n",
       "      <td>0.324859</td>\n",
       "      <td>0.735705</td>\n",
       "      <td>0.115461</td>\n",
       "      <td>7</td>\n",
       "      <td>131</td>\n",
       "      <td>286</td>\n",
       "      <td>0.943087</td>\n",
       "      <td>0.987869</td>\n",
       "      <td>0.834068</td>\n",
       "      <td>0.149161</td>\n",
       "      <td>0.024707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0.054369</td>\n",
       "      <td>0.294559</td>\n",
       "      <td>0.759332</td>\n",
       "      <td>0.110489</td>\n",
       "      <td>7</td>\n",
       "      <td>129</td>\n",
       "      <td>273</td>\n",
       "      <td>0.945674</td>\n",
       "      <td>0.987420</td>\n",
       "      <td>0.831823</td>\n",
       "      <td>0.163995</td>\n",
       "      <td>0.029726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0.054349</td>\n",
       "      <td>0.355920</td>\n",
       "      <td>0.717452</td>\n",
       "      <td>0.120156</td>\n",
       "      <td>7</td>\n",
       "      <td>122</td>\n",
       "      <td>285</td>\n",
       "      <td>0.954400</td>\n",
       "      <td>0.991591</td>\n",
       "      <td>0.870259</td>\n",
       "      <td>0.162126</td>\n",
       "      <td>0.030155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0.054139</td>\n",
       "      <td>0.310530</td>\n",
       "      <td>0.746925</td>\n",
       "      <td>0.113074</td>\n",
       "      <td>7</td>\n",
       "      <td>121</td>\n",
       "      <td>248</td>\n",
       "      <td>0.945357</td>\n",
       "      <td>0.973540</td>\n",
       "      <td>1.017980</td>\n",
       "      <td>0.169048</td>\n",
       "      <td>0.040637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.053994</td>\n",
       "      <td>0.282848</td>\n",
       "      <td>0.771835</td>\n",
       "      <td>0.108323</td>\n",
       "      <td>7</td>\n",
       "      <td>124</td>\n",
       "      <td>241</td>\n",
       "      <td>0.953899</td>\n",
       "      <td>0.974846</td>\n",
       "      <td>0.949731</td>\n",
       "      <td>0.178170</td>\n",
       "      <td>0.049282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0.053989</td>\n",
       "      <td>0.324882</td>\n",
       "      <td>0.736220</td>\n",
       "      <td>0.115453</td>\n",
       "      <td>7</td>\n",
       "      <td>147</td>\n",
       "      <td>318</td>\n",
       "      <td>0.920710</td>\n",
       "      <td>0.990161</td>\n",
       "      <td>0.826833</td>\n",
       "      <td>0.138246</td>\n",
       "      <td>0.020496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.053988</td>\n",
       "      <td>0.270702</td>\n",
       "      <td>0.784720</td>\n",
       "      <td>0.106133</td>\n",
       "      <td>7</td>\n",
       "      <td>121</td>\n",
       "      <td>245</td>\n",
       "      <td>0.949677</td>\n",
       "      <td>0.978327</td>\n",
       "      <td>1.050593</td>\n",
       "      <td>0.177366</td>\n",
       "      <td>0.049374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.053975</td>\n",
       "      <td>0.220568</td>\n",
       "      <td>0.853742</td>\n",
       "      <td>0.095711</td>\n",
       "      <td>7</td>\n",
       "      <td>113</td>\n",
       "      <td>246</td>\n",
       "      <td>0.954576</td>\n",
       "      <td>0.965500</td>\n",
       "      <td>1.013466</td>\n",
       "      <td>0.179208</td>\n",
       "      <td>0.039417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.053903</td>\n",
       "      <td>0.282502</td>\n",
       "      <td>0.772725</td>\n",
       "      <td>0.108304</td>\n",
       "      <td>7</td>\n",
       "      <td>123</td>\n",
       "      <td>239</td>\n",
       "      <td>0.954854</td>\n",
       "      <td>0.967101</td>\n",
       "      <td>1.095675</td>\n",
       "      <td>0.160367</td>\n",
       "      <td>0.045464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0.053878</td>\n",
       "      <td>0.219171</td>\n",
       "      <td>0.855304</td>\n",
       "      <td>0.095442</td>\n",
       "      <td>7</td>\n",
       "      <td>135</td>\n",
       "      <td>301</td>\n",
       "      <td>0.764624</td>\n",
       "      <td>0.994661</td>\n",
       "      <td>0.940250</td>\n",
       "      <td>0.179063</td>\n",
       "      <td>0.037387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number        AP  CV_LogLoss    CV_WLL  params_learning_rate  \\\n",
       "46      46  0.054390    0.324859  0.735705              0.115461   \n",
       "45      45  0.054369    0.294559  0.759332              0.110489   \n",
       "34      34  0.054349    0.355920  0.717452              0.120156   \n",
       "42      42  0.054139    0.310530  0.746925              0.113074   \n",
       "21      21  0.053994    0.282848  0.771835              0.108323   \n",
       "47      47  0.053989    0.324882  0.736220              0.115453   \n",
       "14      14  0.053988    0.270702  0.784720              0.106133   \n",
       "16      16  0.053975    0.220568  0.853742              0.095711   \n",
       "31      31  0.053903    0.282502  0.772725              0.108304   \n",
       "40      40  0.053878    0.219171  0.855304              0.095442   \n",
       "\n",
       "    params_max_depth  params_num_leaves  params_min_data_in_leaf  \\\n",
       "46                 7                131                      286   \n",
       "45                 7                129                      273   \n",
       "34                 7                122                      285   \n",
       "42                 7                121                      248   \n",
       "21                 7                124                      241   \n",
       "47                 7                147                      318   \n",
       "14                 7                121                      245   \n",
       "16                 7                113                      246   \n",
       "31                 7                123                      239   \n",
       "40                 7                135                      301   \n",
       "\n",
       "    params_feature_fraction  params_bagging_fraction  params_lambda_l1  \\\n",
       "46                 0.943087                 0.987869          0.834068   \n",
       "45                 0.945674                 0.987420          0.831823   \n",
       "34                 0.954400                 0.991591          0.870259   \n",
       "42                 0.945357                 0.973540          1.017980   \n",
       "21                 0.953899                 0.974846          0.949731   \n",
       "47                 0.920710                 0.990161          0.826833   \n",
       "14                 0.949677                 0.978327          1.050593   \n",
       "16                 0.954576                 0.965500          1.013466   \n",
       "31                 0.954854                 0.967101          1.095675   \n",
       "40                 0.764624                 0.994661          0.940250   \n",
       "\n",
       "    params_lambda_l2  params_min_split_gain  \n",
       "46          0.149161               0.024707  \n",
       "45          0.163995               0.029726  \n",
       "34          0.162126               0.030155  \n",
       "42          0.169048               0.040637  \n",
       "21          0.178170               0.049282  \n",
       "47          0.138246               0.020496  \n",
       "14          0.177366               0.049374  \n",
       "16          0.179208               0.039417  \n",
       "31          0.160367               0.045464  \n",
       "40          0.179063               0.037387  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Stage-2 — Adaptive narrow tuning from Stage-1 signals\n",
    "# =========================================================\n",
    "import json, copy\n",
    "import numpy as np, pandas as pd, optuna, lightgbm as lgb\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score, log_loss\n",
    "\n",
    "ART_DIR = Path(\"./artifacts/optuna_lgbm/stage2\"); ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- reusable helpers (same as before) ---------------------------------------\n",
    "def stratified_sample(df, n, ycol, seed):\n",
    "    if (n is None) or (n >= len(df)): \n",
    "        return df.sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "    pos = df[df[ycol] == 1]; neg = df[df[ycol] == 0]\n",
    "    r = pos.shape[0] / max(len(df),1); n_pos = max(1, int(round(n*r))); n_neg = n - n_pos\n",
    "    return pd.concat([\n",
    "        pos.sample(min(n_pos, len(pos)), random_state=seed),\n",
    "        neg.sample(min(n_neg, len(neg)), random_state=seed)\n",
    "    ]).sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "def make_clean_frames(train_df, valid_df, feat_cols, cat_cols):\n",
    "    X_tr_clean = train_df[feat_cols].copy()\n",
    "    X_va_clean = valid_df[feat_cols].copy()\n",
    "    y_tr_clean = train_df[TARGET_COL].astype(int).to_numpy()\n",
    "    y_va_clean = valid_df[TARGET_COL].astype(int).to_numpy()\n",
    "    for df in (X_tr_clean, X_va_clean):\n",
    "        obj = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "        if obj: df.drop(columns=obj, inplace=True, errors=\"ignore\")\n",
    "    for c in cat_cols:\n",
    "        if c in X_tr_clean.columns and not pd.api.types.is_categorical_dtype(X_tr_clean[c]):\n",
    "            X_tr_clean[c] = X_tr_clean[c].astype(\"category\")\n",
    "        if c in X_va_clean.columns and not pd.api.types.is_categorical_dtype(X_va_clean[c]):\n",
    "            X_va_clean[c] = X_va_clean[c].astype(\"category\")\n",
    "    return X_tr_clean, y_tr_clean, X_va_clean, y_va_clean\n",
    "\n",
    "def _span(v, lo, hi, rel=0.2):\n",
    "    a = max(lo, v*(1-rel)); b = min(hi, v*(1+rel))\n",
    "    if a >= b:\n",
    "        a = max(lo, v*0.9); b = min(hi, v*1.1)\n",
    "    return float(a), float(b)\n",
    "\n",
    "# --- build adaptive search space from Stage-1 top decile ----------------------\n",
    "df1 = study.trials_dataframe()\n",
    "df1 = df1.assign(AP = -df1[\"value\"])\n",
    "k = max(1, int(np.ceil(len(df1)*0.10)))\n",
    "top = (df1.sort_values(\"value\").head(k)).reset_index(drop=True)\n",
    "\n",
    "best_stage1 = copy.deepcopy(study.best_trial.params)\n",
    "best_lr  = float(best_stage1.get(\"learning_rate\", 0.13))\n",
    "best_md  = int(best_stage1.get(\"max_depth\", 6))\n",
    "best_nl  = int(best_stage1.get(\"num_leaves\", 256))\n",
    "best_mdl = int(best_stage1.get(\"min_data_in_leaf\", 1500))\n",
    "best_ff  = float(best_stage1.get(\"feature_fraction\", 0.75))\n",
    "best_bf  = float(best_stage1.get(\"bagging_fraction\", 0.92))\n",
    "best_l1  = float(best_stage1.get(\"lambda_l1\", 1.0))\n",
    "best_l2  = float(best_stage1.get(\"lambda_l2\", 9.0))\n",
    "best_msg = float(best_stage1.get(\"min_split_gain\", 0.0))\n",
    "use_spw  = bool(best_stage1.get(\"use_scale_pos_weight\", True))\n",
    "\n",
    "def _q(name, q, default):\n",
    "    col = f\"params_{name}\"\n",
    "    return float(top[col].quantile(q)) if col in top.columns and top[col].notna().any() else float(default)\n",
    "\n",
    "lr_lo,  lr_hi  = _span(_q(\"learning_rate\", 0.50, best_lr),   0.01, 0.5, 0.20)\n",
    "md_lo,  md_hi  = int(max(3, best_md-1)), int(min(16, best_md+1))\n",
    "nl_lo,  nl_hi  = int(max(31, best_nl*0.6)), int(min(2047, best_nl*1.4))\n",
    "mdl_lo, mdl_hi = int(max(50, best_mdl*0.6)), int(min(10000, best_mdl*1.4))\n",
    "ff_lo,  ff_hi  = _span(_q(\"feature_fraction\", 0.50, best_ff), 0.5, 1.0, 0.15)\n",
    "bf_lo,  bf_hi  = _span(_q(\"bagging_fraction\", 0.50, best_bf), 0.5, 1.0, 0.10)\n",
    "l1_lo,  l1_hi  = _span(_q(\"lambda_l1\", 0.50, best_l1), 0.0, 10.0, 0.50)\n",
    "l2_lo,  l2_hi  = _span(_q(\"lambda_l2\", 0.50, best_l2), 0.0, 20.0, 0.30)\n",
    "\n",
    "if \"params_min_split_gain\" in top.columns and top[\"params_min_split_gain\"].notna().any():\n",
    "    msg_lo, msg_hi = _span(_q(\"min_split_gain\", 0.50, best_msg), 0.0, 0.2, 0.50)\n",
    "else:\n",
    "    msg_lo, msg_hi = 0.0, 0.05\n",
    "\n",
    "with open(ART_DIR / \"stage2_search_space.json\",\"w\") as f:\n",
    "    json.dump({\n",
    "        \"learning_rate\":[lr_lo, lr_hi],\n",
    "        \"max_depth\":[md_lo, md_hi],\n",
    "        \"num_leaves\":[nl_lo, nl_hi],\n",
    "        \"min_data_in_leaf\":[mdl_lo, mdl_hi],\n",
    "        \"feature_fraction\":[ff_lo, ff_hi],\n",
    "        \"bagging_fraction\":[bf_lo, bf_hi],\n",
    "        \"lambda_l1\":[l1_lo, l1_hi],\n",
    "        \"lambda_l2\":[l2_lo, l2_hi],\n",
    "        \"min_split_gain\":[msg_lo, msg_hi],\n",
    "        \"use_scale_pos_weight\": use_spw\n",
    "    }, f, indent=2)\n",
    "\n",
    "# --- clean frames -------------------------------------------------------------\n",
    "EXCLUDE = {TARGET_COL, SEQ_COL}\n",
    "feat_cols = [c for c in train_df.columns if c not in EXCLUDE]\n",
    "X_tr_clean, y_tr_clean, X_va_clean, y_va_clean = make_clean_frames(train_df, valid_df, feat_cols, CAT_COLS_FIXED)\n",
    "\n",
    "TUNE2_N = 1_500_000\n",
    "tr_tune2 = stratified_sample(train_df, TUNE2_N, TARGET_COL, SEED)\n",
    "Xt2_clean, yt2_clean, _, _ = make_clean_frames(tr_tune2, valid_df, feat_cols, CAT_COLS_FIXED)\n",
    "\n",
    "# imbalance policy consistent with Stage-1 best\n",
    "if use_spw:\n",
    "    pos = int(y_tr_clean.sum()); neg = len(y_tr_clean) - pos\n",
    "    base_spw = float(neg / max(pos, 1))\n",
    "else:\n",
    "    base_spw = None  # will use is_unbalance\n",
    "\n",
    "# --- objective: AP maximize (minimize -AP) + record LogLoss/WLL ---------------\n",
    "def objective_stage2(trial: optuna.trial.Trial) -> float:\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", lr_lo, lr_hi),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", md_lo, md_hi),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", nl_lo, nl_hi, log=True),  # log-scale\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", mdl_lo, mdl_hi, log=True),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", ff_lo, ff_hi),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", bf_lo, bf_hi),\n",
    "        \"bagging_freq\": 1,\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", l1_lo, l1_hi),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", l2_lo, l2_hi),\n",
    "        \"min_split_gain\": trial.suggest_float(\"min_split_gain\", msg_lo, msg_hi),\n",
    "        \"random_state\": SEED, \"n_jobs\": -1, \"verbosity\": -1,\n",
    "    }\n",
    "    if base_spw is not None:\n",
    "        params[\"scale_pos_weight\"] = base_spw\n",
    "    else:\n",
    "        params[\"is_unbalance\"] = True\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "    ap_scores, nll_scores, wll_scores = [], [], []\n",
    "\n",
    "    for tr_idx, va_idx in skf.split(Xt2_clean, yt2_clean):\n",
    "        Xtr, Xcv = Xt2_clean.iloc[tr_idx], Xt2_clean.iloc[va_idx]\n",
    "        ytr, ycv = yt2_clean[tr_idx], yt2_clean[va_idx]\n",
    "\n",
    "        clf = lgb.LGBMClassifier(n_estimators=4000, **params)\n",
    "        clf.fit(\n",
    "            Xtr, ytr,\n",
    "            eval_set=[(Xcv, ycv)],\n",
    "            eval_metric=[\"binary_logloss\", \"aucpr\"],\n",
    "            callbacks=[lgb.early_stopping(150, verbose=False)]\n",
    "        )\n",
    "        p = clf.predict_proba(Xcv)[:, 1]\n",
    "        ap_scores.append(average_precision_score(ycv, p))\n",
    "        nll_scores.append(log_loss(ycv, p))\n",
    "        wll_scores.append(weighted_log_loss(ycv, p, 0.5, 0.5))\n",
    "\n",
    "    trial.set_user_attr(\"cv_logloss\", float(np.mean(nll_scores)))\n",
    "    trial.set_user_attr(\"cv_wll\", float(np.mean(wll_scores)))\n",
    "    return -float(np.mean(ap_scores))\n",
    "\n",
    "study2 = optuna.create_study(direction=\"minimize\", study_name=\"lgbm_stage2_ap\")\n",
    "study2.optimize(objective_stage2, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "df2 = study2.trials_dataframe()\n",
    "topk2 = (df2.assign(AP=-df2[\"value\"],\n",
    "                    CV_LogLoss=df2[\"user_attrs_cv_logloss\"],\n",
    "                    CV_WLL=df2[\"user_attrs_cv_wll\"])\n",
    "              .sort_values(\"value\").head(10))\n",
    "display(topk2[[\"number\",\"AP\",\"CV_LogLoss\",\"CV_WLL\",\n",
    "               \"params_learning_rate\",\"params_max_depth\",\"params_num_leaves\",\n",
    "               \"params_min_data_in_leaf\",\"params_feature_fraction\",\"params_bagging_fraction\",\n",
    "               \"params_lambda_l1\",\"params_lambda_l2\",\"params_min_split_gain\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] Wrote: artifacts/optuna_lgbm/valid_gate_metrics_calibrated.json\n"
     ]
    }
   ],
   "source": [
    "# --- Backfill Stage-1 calibrated metrics JSON (run once) ---\n",
    "import json, numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import average_precision_score, log_loss\n",
    "\n",
    "ART_ROOT = Path(\"./artifacts/optuna_lgbm\")\n",
    "METRICS_JSON = ART_ROOT / \"valid_gate_metrics_calibrated.json\"\n",
    "\n",
    "def _metrics(y, p):\n",
    "    return {\n",
    "        \"AP\": float(average_precision_score(y, p)),\n",
    "        \"LogLoss\": float(log_loss(y, p)),\n",
    "        \"WLL\": float(weighted_log_loss(y, p, 0.5, 0.5)),\n",
    "        \"MeanPred\": float(np.mean(p)),\n",
    "    }\n",
    "\n",
    "FORCE_BACKFILL = True  \n",
    "\n",
    "if METRICS_JSON.exists() and not FORCE_BACKFILL:\n",
    "    print(\"[ok] JSON already exists:\", METRICS_JSON)\n",
    "\n",
    "else:\n",
    "    y_va_clean = valid_df[TARGET_COL].astype(int).to_numpy()\n",
    "\n",
    "    p_base_f = ART_ROOT / \"p_valid_baseline.npy\"\n",
    "    p_uncal_f = ART_ROOT / \"p_valid_uncal.npy\"\n",
    "    p_cal_f   = ART_ROOT / \"p_valid_calibrated.npy\"\n",
    "\n",
    "    if not (p_base_f.exists() and p_uncal_f.exists() and p_cal_f.exists()):\n",
    "        raise FileNotFoundError(\n",
    "            \"Saved prediction files not found. Re-run the Stage-1 Validation Gate cell \"\n",
    "            \"that saves p_valid_baseline.npy / p_valid_uncal.npy / p_valid_calibrated.npy.\"\n",
    "        )\n",
    "\n",
    "    p_base  = np.load(p_base_f)\n",
    "    p_uncal = np.load(p_uncal_f)\n",
    "    p_cal   = np.load(p_cal_f)\n",
    "\n",
    "    out = {\n",
    "        \"base\": _metrics(y_va_clean, p_base),\n",
    "        \"uncal\": _metrics(y_va_clean, p_uncal),\n",
    "        \"cal\": _metrics(y_va_clean, p_cal),\n",
    "        \"base_rate\": float(y_va_clean.mean()),\n",
    "    }\n",
    "    METRICS_JSON.write_text(json.dumps(out, indent=2))\n",
    "    print(\"[ok] Wrote:\", METRICS_JSON)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hg/v9v4slf113jb0w4kpzx5y_zw0000gn/T/ipykernel_77034/2581621568.py:32: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if c in X_tr_clean.columns and not pd.api.types.is_categorical_dtype(X_tr_clean[c]):\n",
      "/var/folders/hg/v9v4slf113jb0w4kpzx5y_zw0000gn/T/ipykernel_77034/2581621568.py:34: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if c in X_va_clean.columns and not pd.api.types.is_categorical_dtype(X_va_clean[c]):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AP</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>WLL</th>\n",
       "      <th>MeanPred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stage-2 + Isotonic(OOF)</td>\n",
       "      <td>0.057314</td>\n",
       "      <td>0.088283</td>\n",
       "      <td>1.832454</td>\n",
       "      <td>0.019106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stage-1 Calibrated (prev)</td>\n",
       "      <td>0.055251</td>\n",
       "      <td>0.088486</td>\n",
       "      <td>1.835594</td>\n",
       "      <td>0.019183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stage-2 Uncalibrated</td>\n",
       "      <td>0.057951</td>\n",
       "      <td>0.322766</td>\n",
       "      <td>0.722807</td>\n",
       "      <td>0.240202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model        AP   LogLoss       WLL  MeanPred\n",
       "0    Stage-2 + Isotonic(OOF)  0.057314  0.088283  1.832454  0.019106\n",
       "1  Stage-1 Calibrated (prev)  0.055251  0.088486  1.835594  0.019183\n",
       "2       Stage-2 Uncalibrated  0.057951  0.322766  0.722807  0.240202"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage-2 Gate] ΔAP = +0.002063, ΔLogLoss = -0.000203 (negative is better)\n",
      "[Decision] Finalize Stage-2? YES\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Stage-2 — Validation Gate with OOF Isotonic calibration\n",
    "# =========================================================\n",
    "import json, copy\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from joblib import dump\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score, log_loss\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "import lightgbm as lgb\n",
    "\n",
    "ART_ROOT = Path(\"./artifacts/optuna_lgbm\")\n",
    "ART_DIR  = ART_ROOT / \"stage2\"; ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "METRICS_JSON = ART_ROOT / \"valid_gate_metrics_calibrated.json\"\n",
    "\n",
    "def compute_metrics(y_true, p):\n",
    "    return {\n",
    "        \"AP\": average_precision_score(y_true, p),\n",
    "        \"LogLoss\": log_loss(y_true, p),\n",
    "        \"WLL\": weighted_log_loss(y_true, p, 0.5, 0.5)\n",
    "    }\n",
    "\n",
    "# prior calibrated metrics from Stage-1\n",
    "try:\n",
    "    prev = json.loads(METRICS_JSON.read_text())\n",
    "    m_prev_cal = prev[\"cal\"]\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\n",
    "        f\"{METRICS_JSON} not found.\\n\"\n",
    "        \"Run the backfill cell (or re-run the Stage-1 Validation Gate cell that saves \"\n",
    "        \"'p_valid_baseline.npy', 'p_valid_uncal.npy', 'p_valid_calibrated.npy') \"\n",
    "        \"to generate this JSON.\"\n",
    "    )\n",
    "\n",
    "# frames (clean)\n",
    "EXCLUDE = {TARGET_COL, SEQ_COL}\n",
    "feat_cols = [c for c in train_df.columns if c not in EXCLUDE]\n",
    "X_tr_clean, y_tr_clean, X_va_clean, y_va_clean = make_clean_frames(train_df, valid_df, feat_cols, CAT_COLS_FIXED)\n",
    "\n",
    "# reconstruct best params from Stage-2\n",
    "best2 = copy.deepcopy(study2.best_trial.params)\n",
    "if bool(study.best_trial.params.get(\"use_scale_pos_weight\", True)):\n",
    "    pos = int(y_tr_clean.sum()); neg = len(y_tr_clean) - pos\n",
    "    imb = {\"scale_pos_weight\": float(neg / max(pos, 1))}\n",
    "else:\n",
    "    imb = {\"is_unbalance\": True}\n",
    "\n",
    "best_full = {\n",
    "    \"objective\":\"binary\", \"metric\":\"binary_logloss\", \"random_state\":SEED, \"n_jobs\":-1, \"bagging_freq\":1,\n",
    "    **best2, **imb\n",
    "}\n",
    "(ART_DIR / \"best_params_stage2.json\").write_text(json.dumps(best_full, indent=2))\n",
    "\n",
    "# OOF isotonic\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "oof = np.zeros_like(y_tr_clean, dtype=float)\n",
    "for tr_idx, va_idx in skf.split(X_tr_clean, y_tr_clean):\n",
    "    clf_cv = lgb.LGBMClassifier(n_estimators=4000, **best_full)\n",
    "    clf_cv.fit(\n",
    "        X_tr_clean.iloc[tr_idx], y_tr_clean[tr_idx],\n",
    "        eval_set=[(X_tr_clean.iloc[va_idx], y_tr_clean[va_idx])],\n",
    "        eval_metric=[\"binary_logloss\",\"aucpr\"],\n",
    "        callbacks=[lgb.early_stopping(150, verbose=False)]\n",
    "    )\n",
    "    oof[va_idx] = clf_cv.predict_proba(X_tr_clean.iloc[va_idx])[:, 1]\n",
    "\n",
    "iso = IsotonicRegression(y_min=0.0, y_max=1.0, out_of_bounds=\"clip\").fit(oof, y_tr_clean)\n",
    "dump(iso, ART_DIR / \"isotonic_stage2.joblib\")\n",
    "\n",
    "# full-train fit → calibrated valid\n",
    "lgb_s2 = lgb.LGBMClassifier(n_estimators=6000, **best_full)\n",
    "lgb_s2.fit(\n",
    "    X_tr_clean, y_tr_clean,\n",
    "    eval_set=[(X_va_clean, y_va_clean)],\n",
    "    eval_metric=[\"binary_logloss\",\"aucpr\"],\n",
    "    callbacks=[lgb.early_stopping(200, verbose=False)]\n",
    ")\n",
    "p_uncal = lgb_s2.predict_proba(X_va_clean)[:, 1]\n",
    "p_cal   = iso.transform(p_uncal)\n",
    "\n",
    "m_uncal = compute_metrics(y_va_clean, p_uncal)\n",
    "m_cal   = compute_metrics(y_va_clean, p_cal)\n",
    "\n",
    "cmp = (pd.DataFrame([\n",
    "    {\"Model\":\"Stage-1 Calibrated (prev)\", **m_prev_cal, \"MeanPred\": float(m_prev_cal.get(\"MeanPred\", np.nan))},\n",
    "    {\"Model\":\"Stage-2 Uncalibrated\",     **m_uncal,    \"MeanPred\": float(p_uncal.mean())},\n",
    "    {\"Model\":\"Stage-2 + Isotonic(OOF)\",  **m_cal,      \"MeanPred\": float(p_cal.mean())},\n",
    "])[[\"Model\",\"AP\",\"LogLoss\",\"WLL\",\"MeanPred\"]]\n",
    " .sort_values([\"LogLoss\",\"AP\"], ascending=[True, False])\n",
    " .reset_index(drop=True))\n",
    "display(cmp)\n",
    "\n",
    "delta_ap = m_cal[\"AP\"] - m_prev_cal[\"AP\"]\n",
    "delta_ll = m_cal[\"LogLoss\"] - m_prev_cal[\"LogLoss\"]  # negative is better\n",
    "print(f\"[Stage-2 Gate] ΔAP = {delta_ap:+.6f}, ΔLogLoss = {delta_ll:+.6f} (negative is better)\")\n",
    "\n",
    "cmp.to_csv(ART_DIR / \"valid_gate_comparison_stage2.csv\", index=False)\n",
    "with open(ART_DIR / \"valid_gate_metrics_stage2.json\",\"w\") as f:\n",
    "    json.dump({\"stage1_calibrated\": m_prev_cal, \"stage2_uncal\": m_uncal, \"stage2_cal\": m_cal,\n",
    "               \"delta_ap\": float(delta_ap), \"delta_logloss\": float(delta_ll)}, f, indent=2)\n",
    "\n",
    "from joblib import dump\n",
    "dump(lgb_s2, ART_DIR / \"model_stage2_best_valid_uncal.joblib\")\n",
    "np.save(ART_DIR / \"p_valid_stage2_uncal.npy\", p_uncal)\n",
    "np.save(ART_DIR / \"p_valid_stage2_calibrated.npy\", p_cal)\n",
    "\n",
    "AP_GAIN_MIN = 0.001\n",
    "ALLOW_LL_WORSE = False\n",
    "promote = (delta_ap >= AP_GAIN_MIN) and (ALLOW_LL_WORSE or (delta_ll <= 0))\n",
    "print(f\"[Decision] Finalize Stage-2? {'YES' if promote else 'NO'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage-2 — Summary\n",
    "- Objective: refine top-decile trials to improve **AP** without hurting **LogLoss**.\n",
    "- Valid (calibrated): **AP 0.0573** (+0.0021 vs S1), **LogLoss 0.0883** (−0.0002), MeanPred **0.0191** (~base 0.019).\n",
    "- Decision: ✅ Proceed to Stage-3 (full-train + isotonic + holdout).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hg/v9v4slf113jb0w4kpzx5y_zw0000gn/T/ipykernel_77034/1931688018.py:21: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(X_tr_clean[c]):\n",
      "/var/folders/hg/v9v4slf113jb0w4kpzx5y_zw0000gn/T/ipykernel_77034/1931688018.py:24: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(X_te_clean[c]):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AP</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>WLL</th>\n",
       "      <th>MeanPred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Final+Isotonic(OOF from train)</td>\n",
       "      <td>0.058635</td>\n",
       "      <td>0.091558</td>\n",
       "      <td>2.060359</td>\n",
       "      <td>0.013497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Final(Uncalibrated)</td>\n",
       "      <td>0.063388</td>\n",
       "      <td>0.216802</td>\n",
       "      <td>1.014174</td>\n",
       "      <td>0.148005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model        AP   LogLoss       WLL  MeanPred\n",
       "0  Final+Isotonic(OOF from train)  0.058635  0.091558  2.060359  0.013497\n",
       "1             Final(Uncalibrated)  0.063388  0.216802  1.014174  0.148005"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Holdout base rate] 0.019075\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Stage-3 — Final model (full train) & one-shot holdout eval (no leakage)\n",
    "# =========================================================\n",
    "import json, copy, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from joblib import load, dump\n",
    "from sklearn.metrics import average_precision_score, log_loss\n",
    "import lightgbm as lgb\n",
    "\n",
    "# --- helpers reused ---\n",
    "def prepare_lgb_frames(X_tr_src, X_te_src, cat_cols):\n",
    "    X_tr_clean = X_tr_src.copy()\n",
    "    X_te_clean = X_te_src.copy()\n",
    "    # drop stray objects\n",
    "    obj_tr = X_tr_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "    obj_te = X_te_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "    if obj_tr: X_tr_clean.drop(columns=obj_tr, inplace=True, errors=\"ignore\")\n",
    "    if obj_te: X_te_clean.drop(columns=obj_te, inplace=True, errors=\"ignore\")\n",
    "    # categorical casting\n",
    "    for c in [c for c in cat_cols if c in X_tr_clean.columns]:\n",
    "        if not pd.api.types.is_categorical_dtype(X_tr_clean[c]):\n",
    "            X_tr_clean[c] = X_tr_clean[c].astype(\"category\")\n",
    "    for c in [c for c in cat_cols if c in X_te_clean.columns]:\n",
    "        if not pd.api.types.is_categorical_dtype(X_te_clean[c]):\n",
    "            X_te_clean[c] = X_te_clean[c].astype(\"category\")\n",
    "    return X_tr_clean, X_te_clean\n",
    "\n",
    "def compute_metrics_simple(y_true, p):\n",
    "    return {\n",
    "        \"AP\": float(average_precision_score(y_true, p)),\n",
    "        \"LogLoss\": float(log_loss(y_true, p)),\n",
    "        \"WLL\": float(weighted_log_loss(y_true, p, 0.5, 0.5)),\n",
    "        \"MeanPred\": float(np.mean(p))\n",
    "    }\n",
    "\n",
    "# --- frames: full train -> holdout (no valid usage here) ---------------------\n",
    "EXCLUDE = {TARGET_COL, SEQ_COL}\n",
    "feat_cols = [c for c in train_df.columns if c not in EXCLUDE]\n",
    "\n",
    "X_full_tr = train_df[feat_cols]\n",
    "y_full_tr = train_df[TARGET_COL].astype(int).to_numpy()\n",
    "\n",
    "# holdout must exist (labels optional for real competitions; here we have y_ho)\n",
    "assert X_ho is not None, \"holdout_df (X_ho) is required for final evaluation.\"\n",
    "X_tr_clean, X_ho_clean = prepare_lgb_frames(X_full_tr, X_ho, CAT_COLS_FIXED)\n",
    "\n",
    "# --- best params from Stage-2 (fallback to Stage-1 if Stage-2 absent) --------\n",
    "ART_ROOT = Path(\"./artifacts/optuna_lgbm\")\n",
    "S2_DIR   = ART_ROOT / \"stage2\"\n",
    "S2_PARAMS = S2_DIR / \"best_params_stage2.json\"\n",
    "\n",
    "if S2_PARAMS.exists():\n",
    "    best_params = json.loads(S2_PARAMS.read_text())\n",
    "else:\n",
    "    # fallback: use Stage-1 gate (saved before)\n",
    "    best_params = json.loads((ART_ROOT / \"best_params_valid_gate.json\").read_text())\n",
    "\n",
    "# IMPORTANT: final training must NOT use valid for early stopping\n",
    "# Use a generous n_estimators; no eval_set\n",
    "n_estimators_final = 6000\n",
    "lgb_final = lgb.LGBMClassifier(n_estimators=n_estimators_final, **best_params)\n",
    "\n",
    "lgb_final.fit(X_tr_clean, y_full_tr)\n",
    "\n",
    "# --- load isotonic fitted on train-OOF (Stage-2 preferred) -------------------\n",
    "ISO_S2 = S2_DIR / \"isotonic_stage2.joblib\"\n",
    "ISO_S1 = ART_ROOT / \"isotonic_stage1.joblib\"\n",
    "if ISO_S2.exists():\n",
    "    iso = load(ISO_S2)\n",
    "elif ISO_S1.exists():\n",
    "    iso = load(ISO_S1)\n",
    "else:\n",
    "    raise FileNotFoundError(\"Isotonic from Stage-1/2 not found. Run Stage-2 (or Stage-1) gate first.\")\n",
    "\n",
    "# --- predict holdout once (uncalibrated -> calibrated) -----------------------\n",
    "p_ho_uncal = lgb_final.predict_proba(X_ho_clean)[:, 1]\n",
    "p_ho_cal   = iso.transform(p_ho_uncal)\n",
    "\n",
    "# if holdout labels are present, compute metrics; else just save preds\n",
    "results = {}\n",
    "if y_ho is not None:\n",
    "    m_uncal = compute_metrics_simple(y_ho, p_ho_uncal)\n",
    "    m_cal   = compute_metrics_simple(y_ho, p_ho_cal)\n",
    "    holdout_report = (\n",
    "        pd.DataFrame([\n",
    "            {\"Model\":\"Final(Uncalibrated)\", **m_uncal},\n",
    "            {\"Model\":\"Final+Isotonic(OOF from train)\", **m_cal},\n",
    "        ])\n",
    "        .sort_values([\"LogLoss\",\"AP\"], ascending=[True, False])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    display(holdout_report)\n",
    "\n",
    "    results = {\"uncal\": m_uncal, \"cal\": m_cal}\n",
    "    print(f\"[Holdout base rate] {y_ho.mean():.6f}\")\n",
    "else:\n",
    "    print(\"[Info] Holdout labels are missing; saving predictions only.\")\n",
    "\n",
    "# --- save artifacts ----------------------------------------------------------\n",
    "OUT_DIR = ART_ROOT / \"final\"; OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "dump(lgb_final, OUT_DIR / \"model_lgb_final.joblib\")\n",
    "np.save(OUT_DIR / \"p_holdout_uncal.npy\", p_ho_uncal)\n",
    "np.save(OUT_DIR / \"p_holdout_calibrated.npy\", p_ho_cal)\n",
    "(Path(OUT_DIR / \"final_params.json\")).write_text(json.dumps({\"n_estimators\": n_estimators_final, **best_params}, indent=2))\n",
    "if results:\n",
    "    (OUT_DIR / \"holdout_metrics.json\").write_text(json.dumps(results, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage-3 — Final & Holdout\n",
    "- Train: full 7.28M; Calibration: isotonic on train OOF.\n",
    "- Holdout (calibrated): **AP 0.0586**, **LogLoss 0.0916**, MeanPred **0.0135** (base **0.0191**) → slight under-confidence.\n",
    "- Decision: use **calibrated** probs for thresholds/KPI\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
